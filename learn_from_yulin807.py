#!/usr/bin/env python3
"""
Twitter KOL å­¦ä¹ ç›‘æ§ - @YuLin807
å­¦ä¹ ç›®æ ‡ï¼šäº¤æ˜“åˆ†æã€å¸‚åœºæ´å¯Ÿã€æ–¹æ³•è®º
"""

import os
import re
import json
from datetime import datetime
from typing import List, Dict

class YuLin807Learner:
    """YuLin807 å­¦ä¹ åˆ†æå™¨"""
    
    def __init__(self):
        self.target_user = "YuLin807"
        self.learning_file = "/tmp/yulin807_learning.json"
        
        # å­¦ä¹ ç»´åº¦
        self.dimensions = {
            'market_analysis': 'å¸‚åœºåˆ†æèƒ½åŠ›',
            'trading_psychology': 'äº¤æ˜“å¿ƒç†',
            'risk_management': 'é£é™©ç®¡ç†',
            'technical_skills': 'æŠ€æœ¯åˆ†æ',
            'narrative_sensing': 'å™äº‹æ„ŸçŸ¥',
            'sentiment_analysis': 'æƒ…ç»ªåˆ¤æ–­'
        }
        
        # ç§¯ç´¯çš„çŸ¥è¯†åº“
        self.knowledge_base = {
            'patterns': [],  # å‘ç°çš„æ¨¡å¼
            'quotes': [],    # ç»å…¸è¯­å½•
            'methods': [],   # æ–¹æ³•è®º
            'warnings': [],  # é£é™©æé†’
            'insights': []   # æ´å¯Ÿ
        }
    
    def analyze_tweet_for_learning(self, tweet_text: str, metadata: Dict = None) -> Dict:
        """ä»æ¨æ–‡å­¦ä¹ """
        
        analysis = {
            'raw_text': tweet_text,
            'timestamp': datetime.now().isoformat(),
            'learning_points': [],
            'category': 'general',
            'key_insights': [],
            'actionable_items': [],
            'my_reflection': ''
        }
        
        text_lower = tweet_text.lower()
        
        # 1. è¯†åˆ«å†…å®¹ç±»å‹
        if any(w in text_lower for w in ['btc', 'bitcoin', 'eth', 'ethereum', 'crypto', 'coin']):
            analysis['category'] = 'market_analysis'
        elif any(w in text_lower for w in ['psychology', 'emotion', 'fomo', 'fear', 'greed']):
            analysis['category'] = 'trading_psychology'
        elif any(w in text_lower for w in ['risk', 'stop loss', 'position', 'size']):
            analysis['category'] = 'risk_management'
        elif any(w in text_lower for w in ['chart', 'pattern', 'support', 'resistance', 'ta']):
            analysis['category'] = 'technical_skills'
        elif any(w in text_lower for w in ['narrative', 'story', 'theme', 'trend']):
            analysis['category'] = 'narrative_sensing'
        
        # 2. æå–å­¦ä¹ æ–¹æ³•è®º
        # å¯»æ‰¾"å¦‚ä½•..."ã€"ä¸ºä»€ä¹ˆ..."ã€"å…³é”®æ˜¯..."ç­‰å¥å¼
        teaching_patterns = [
            r'(?:å…³é”®|è¦ç‚¹|æ ¸å¿ƒ)æ˜¯[ï¼š:]\s*([^ã€‚\n]+)',
            r'(?:å­¦ä¼š|æŒæ¡|ç†è§£)[äº†]?\s*([^ï¼Œã€‚\n]+)',
            r'(?:è®°ä½|ç‰¢è®°)[ï¼š:]\s*([^ã€‚\n]+)',
            r'(?:åŸå› |ç†ç”±)æ˜¯[ï¼š:]\s*([^ã€‚\n]+)',
            r'(?:å»ºè®®|æé†’)[ï¼š:]\s*([^ã€‚\n]+)',
        ]
        
        for pattern in teaching_patterns:
            matches = re.findall(pattern, tweet_text, re.IGNORECASE)
            for match in matches:
                analysis['learning_points'].append({
                    'type': 'methodology',
                    'content': match.strip(),
                    'source_quote': tweet_text[max(0, tweet_text.find(match)-20):tweet_text.find(match)+len(match)+20]
                })
        
        # 3. æå–é£é™©æé†’
        risk_keywords = ['é£é™©', 'å°å¿ƒ', 'æ³¨æ„', 'è­¦å‘Š', 'avoid', 'å°å¿ƒ', 'è°¨æ…', 'risk', 'warning']
        if any(kw in text_lower for kw in risk_keywords):
            analysis['learning_points'].append({
                'type': 'risk_warning',
                'content': 'åŒ…å«é£é™©æé†’',
                'full_context': tweet_text
            })
        
        # 4. æå–æ´å¯Ÿ
        insight_patterns = [
            r'(?:å‘ç°|æ„è¯†åˆ°|æ˜ç™½)[äº†]?\s*([^ã€‚\n]+)',
            r'(?:åŸæ¥|å…¶å®)[ï¼Œ]?\s*([^ã€‚\n]+)',
            r'(?:çœŸç›¸|æœ¬è´¨)æ˜¯[ï¼š:]\s*([^ã€‚\n]+)',
        ]
        
        for pattern in insight_patterns:
            matches = re.findall(pattern, tweet_text, re.IGNORECASE)
            for match in matches:
                analysis['key_insights'].append(match.strip())
        
        # 5. ç”Ÿæˆæˆ‘çš„åæ€
        analysis['my_reflection'] = self._generate_reflection(analysis)
        
        # 6. å¯æ‰§è¡Œé¡¹
        analysis['actionable_items'] = self._extract_actionable_items(tweet_text)
        
        return analysis
    
    def _generate_reflection(self, analysis: Dict) -> str:
        """ç”Ÿæˆå­¦ä¹ åæ€"""
        reflections = []
        
        category = analysis['category']
        learning_points = analysis['learning_points']
        
        if category == 'market_analysis':
            reflections.append("å¸‚åœºåˆ†æè¦ç‚¹ï¼šå¦‚ä½•è§£è¯»å½“å‰è¡Œæƒ…")
        elif category == 'trading_psychology':
            reflections.append("äº¤æ˜“å¿ƒç†ï¼šæƒ…ç»ªç®¡ç†çš„é‡è¦æ€§")
        elif category == 'risk_management':
            reflections.append("é£é™©ç®¡ç†ï¼šä¿æŠ¤æœ¬é‡‘æ˜¯ç¬¬ä¸€è¦åŠ¡")
        elif category == 'narrative_sensing':
            reflections.append("å™äº‹æ„ŸçŸ¥ï¼šæŠ“ä½å¸‚åœºä¸»çº¿")
        
        if learning_points:
            reflections.append(f"å­¦åˆ° {len(learning_points)} ä¸ªçŸ¥è¯†ç‚¹")
        
        return "ï¼›".join(reflections) if reflections else "æŒç»­å­¦ä¹ ä¸­"
    
    def _extract_actionable_items(self, text: str) -> List[str]:
        """æå–å¯æ‰§è¡Œçš„å»ºè®®"""
        items = []
        
        # å¯»æ‰¾å»ºè®®æ€§è¯­å¥
        patterns = [
            r'(?:å»ºè®®|åº”è¯¥|å¯ä»¥|è¯•è¯•)[ï¼š:]?\s*([^ã€‚\n]+)',
            r'(?:å…³æ³¨|è§‚å¯Ÿ|æ³¨æ„)[ï¼š:]?\s*([^ã€‚\n]+)',
            r'(?:ä¸è¦|é¿å…|åˆ‡å‹¿)\s*([^ã€‚\n]+)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                items.append(match.strip())
        
        return items[:3]  # æœ€å¤š3æ¡
    
    def generate_learning_report(self, analyses: List[Dict]) -> str:
        """ç”Ÿæˆå­¦ä¹ æŠ¥å‘Š"""
        lines = [
            "ğŸ“š YuLin807 å­¦ä¹ ç¬”è®°",
            f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "=" * 60,
            ""
        ]
        
        # æŒ‰ç±»åˆ«åˆ†ç»„
        by_category = {}
        for a in analyses:
            cat = a['category']
            if cat not in by_category:
                by_category[cat] = []
            by_category[cat].append(a)
        
        # å„åˆ†ç±»æ€»ç»“
        for cat, items in by_category.items():
            cat_name = self.dimensions.get(cat, cat)
            lines.append(f"\nğŸ¯ {cat_name} ({len(items)}æ¡)")
            lines.append("-" * 40)
            
            for i, item in enumerate(items[:3], 1):  # æ¯ç±»æœ€å¤š3æ¡
                lines.append(f"\n  {i}. åŸæ–‡æ‘˜å½•:")
                lines.append(f"     {item['raw_text'][:100]}...")
                
                if item['learning_points']:
                    lines.append(f"     ğŸ’¡ å­¦ä¹ ç‚¹:")
                    for lp in item['learning_points'][:2]:
                        lines.append(f"        â€¢ {lp['content'][:60]}")
                
                if item['key_insights']:
                    lines.append(f"     ğŸ” æ´å¯Ÿ:")
                    for insight in item['key_insights'][:2]:
                        lines.append(f"        â€¢ {insight[:60]}")
                
                if item['actionable_items']:
                    lines.append(f"     âœ… å¯æ‰§è¡Œ:")
                    for action in item['actionable_items']:
                        lines.append(f"        â†’ {action[:60]}")
        
        # æ€»ä½“åæ€
        lines.append(f"\n{'='*60}")
        lines.append("ğŸ¤” æˆ‘çš„æ€»ä½“åæ€:")
        
        all_insights = []
        for a in analyses:
            all_insights.extend(a['key_insights'])
        
        if all_insights:
            lines.append("ä»YuLin807çš„æ¨æ–‡å­¦åˆ°çš„æ ¸å¿ƒæ´å¯Ÿ:")
            for insight in all_insights[:5]:
                lines.append(f"  â€¢ {insight}")
        else:
            lines.append("æŒç»­è§‚å¯Ÿä¸­ï¼Œç§¯ç´¯æ›´å¤šå¸‚åœºæ™ºæ…§...")
        
        lines.append(f"\n{'='*60}")
        lines.append("ğŸ’­ å­¦ä¹ æ–¹æ³•: è®°å½•-åæ€-å®è·µ-å¤ç›˜")
        
        return "\n".join(lines)
    
    def save_learning(self, analysis: Dict):
        """ä¿å­˜å­¦ä¹ å†…å®¹"""
        learnings = []
        if os.path.exists(self.learning_file):
            try:
                with open(self.learning_file, 'r') as f:
                    learnings = json.load(f)
            except:
                pass
        
        learnings.append(analysis)
        
        with open(self.learning_file, 'w') as f:
            json.dump(learnings[-50:], f, indent=2)  # ä¿ç•™æœ€è¿‘50æ¡
    
    def get_learning_summary(self) -> str:
        """è·å–å­¦ä¹ æ€»ç»“"""
        if not os.path.exists(self.learning_file):
            return "æš‚æ— å­¦ä¹ è®°å½•"
        
        try:
            with open(self.learning_file, 'r') as f:
                learnings = json.load(f)
            
            total = len(learnings)
            categories = {}
            for l in learnings:
                cat = l['category']
                categories[cat] = categories.get(cat, 0) + 1
            
            lines = [
                f"ğŸ“Š YuLin807 å­¦ä¹ ç»Ÿè®¡",
                f"æ€»å­¦ä¹ æ¨æ–‡: {total}",
                f"åˆ†ç±»åˆ†å¸ƒ:"
            ]
            
            for cat, count in sorted(categories.items(), key=lambda x: -x[1]):
                cat_name = self.dimensions.get(cat, cat)
                lines.append(f"  â€¢ {cat_name}: {count}")
            
            return "\n".join(lines)
        except:
            return "å­¦ä¹ è®°å½•è¯»å–å¤±è´¥"


def main():
    """æµ‹è¯•å­¦ä¹ åˆ†æ"""
    learner = YuLin807Learner()
    
    # æ¨¡æ‹Ÿæµ‹è¯•æ¨æ–‡
    test_tweets = [
        "å…³é”®æ˜¯æ§åˆ¶é£é™©ï¼Œæ°¸è¿œä¸è¦æŠŠæ‰€æœ‰èµ„é‡‘æ”¾åœ¨ä¸€ä¸ªä»“ä½ä¸Š",
        "FOMOæƒ…ç»ªæ˜¯æœ€å±é™©çš„ï¼Œè®°ä½ï¼šå¸‚åœºæ°¸è¿œæœ‰æœºä¼š",
        "è¿™ä¸ªå™äº‹ä¸é”™ï¼Œä½†éœ€è¦è§‚å¯Ÿæˆäº¤é‡æ˜¯å¦é…åˆ",
        "å»ºè®®å…³æ³¨BTCåœ¨4ä¸‡ç¾é‡‘çš„æ”¯æ’‘æƒ…å†µ"
    ]
    
    analyses = []
    for tweet in test_tweets:
        analysis = learner.analyze_tweet_for_learning(tweet)
        analyses.append(analysis)
        learner.save_learning(analysis)
    
    report = learner.generate_learning_report(analyses)
    print(report)
    
    print("\n" + "="*60)
    print(learner.get_learning_summary())


if __name__ == "__main__":
    main()
