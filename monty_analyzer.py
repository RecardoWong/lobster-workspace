#!/usr/bin/env python3
"""
ğŸ§  Monty Analyzer - é€šç”¨ AI åˆ†æå·¥å…·
å®‰å…¨æ‰§è¡Œ AI ç”Ÿæˆçš„ Python ä»£ç ï¼Œç”¨äºæ•°æ®åˆ†æã€æƒ…ç»ªåˆ¤æ–­ã€é£é™©è¯„ä¼°ç­‰
"""

import pydantic_monty
import json
from typing import Any, Dict, List, Callable, Optional
from datetime import datetime

class MontyAnalyzer:
    """
    é€šç”¨ Monty åˆ†æå·¥å…·
    æ‰€æœ‰ç›‘æ§ä»»åŠ¡éƒ½å¯ä»¥è°ƒç”¨è¿™ä¸ªç±»è¿›è¡Œ AI åˆ†æ
    """
    
    def __init__(self):
        self.execution_log = []
    
    def analyze(self, code: str, inputs: Dict[str, Any], 
                external_functions: Optional[Dict[str, Callable]] = None,
                description: str = "") -> Dict[str, Any]:
        """
        é€šç”¨åˆ†ææ–¹æ³•
        
        Args:
            code: Python ä»£ç å­—ç¬¦ä¸²
            inputs: è¾“å…¥æ•°æ®å­—å…¸
            external_functions: å¤–éƒ¨å‡½æ•°å­—å…¸ {name: function}
            description: åˆ†ææè¿°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        
        Returns:
            {
                'success': bool,
                'result': Any,  # åˆ†æç»“æœ
                'execution_time_ms': float,
                'error': str,  # å¦‚æœå¤±è´¥
                'description': str
            }
        """
        start_time = datetime.now()
        
        try:
            # åˆ›å»º Monty å®ä¾‹
            input_keys = list(inputs.keys())
            ext_func_names = list(external_functions.keys()) if external_functions else []
            
            m = pydantic_monty.Monty(
                code,
                inputs=input_keys,
                external_functions=ext_func_names
            )
            
            # æ‰§è¡Œ
            if external_functions:
                result = m.run(inputs=inputs, external_functions=external_functions)
            else:
                result = m.run(inputs=inputs)
            
            execution_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # è®°å½•æ—¥å¿—
            log_entry = {
                'time': datetime.now().isoformat(),
                'description': description,
                'execution_time_ms': execution_time,
                'success': True,
                'result_preview': str(result)[:100] if result else None
            }
            self.execution_log.append(log_entry)
            
            return {
                'success': True,
                'result': result,
                'execution_time_ms': execution_time,
                'error': None,
                'description': description
            }
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds() * 1000
            
            log_entry = {
                'time': datetime.now().isoformat(),
                'description': description,
                'execution_time_ms': execution_time,
                'success': False,
                'error': str(e)
            }
            self.execution_log.append(log_entry)
            
            return {
                'success': False,
                'result': None,
                'execution_time_ms': execution_time,
                'error': str(e),
                'description': description
            }
    
    # ==================== é¢„ç½®åˆ†ææ–¹æ³• ====================
    
    def analyze_tokens(self, tokens: List[Dict]) -> Dict[str, Any]:
        """
        åˆ†æ Meme å¸æ•°æ®
        ç”¨äº: XXYY.io ç›‘æ§
        """
        code = '''
# Meme å¸æ•°æ®åˆ†æ
total_holders = 0
total_mc = 0
max_holders = 0
max_symbol = ''
hot_tokens = []
narrative_counts = {}

for token in tokens:
    h = token['holders']
    mc = token['mc']
    sym = token['symbol']
    nar = token.get('narrative', 'å…¶ä»–')
    
    total_holders = total_holders + h
    total_mc = total_mc + mc
    
    if h > max_holders:
        max_holders = h
        max_symbol = sym
    
    if h >= 200:
        hot_tokens.append(sym)
    
    if nar in narrative_counts:
        narrative_counts[nar] = narrative_counts[nar] + 1
    else:
        narrative_counts[nar] = 1

avg_holders = total_holders / len(tokens) if tokens else 0
avg_mc = total_mc / len(tokens) if tokens else 0

{
    'total_tokens': len(tokens),
    'avg_holders': avg_holders,
    'avg_mc': avg_mc,
    'hottest_token': max_symbol,
    'hottest_holders': max_holders,
    'hot_tokens': hot_tokens,
    'narrative_distribution': narrative_counts,
    'risk_score': len(hot_tokens) / len(tokens) if tokens else 0
}
'''
        return self.analyze(code, {'tokens': tokens}, description="Memeå¸æ•°æ®åˆ†æ")
    
    def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """
        æƒ…ç»ªåˆ†æ
        ç”¨äº: Twitter æ¨æ–‡åˆ†æ
        """
        code = '''
# æƒ…ç»ªåˆ†æ
positive_words = ['good', 'great', 'amazing', 'excellent', 'love', 'best', 'bullish', 'moon', 'pump']
negative_words = ['bad', 'terrible', 'worst', 'hate', 'bearish', 'dump', 'crash', 'scam', 'rug']

text_lower = text.lower()
positive_count = 0
negative_count = 0

for word in positive_words:
    if word in text_lower:
        positive_count = positive_count + 1

for word in negative_words:
    if word in text_lower:
        negative_count = negative_count + 1

score = positive_count - negative_count

if score > 0:
    sentiment = 'çœ‹æ¶¨/ç§¯æ'
elif score < 0:
    sentiment = 'çœ‹è·Œ/æ¶ˆæ'
else:
    sentiment = 'ä¸­æ€§'

{
    'sentiment': sentiment,
    'score': score,
    'positive_count': positive_count,
    'negative_count': negative_count,
    'text_length': len(text)
}
'''
        return self.analyze(code, {'text': text}, description=f"æ¨æ–‡æƒ…ç»ªåˆ†æ: {text[:50]}...")
    
    def analyze_portfolio(self, holdings: List[Dict]) -> Dict[str, Any]:
        """
        æŠ•èµ„ç»„åˆé£é™©è¯„ä¼°
        ç”¨äº: è‚¡ç¥¨ç›‘æ§
        """
        code = '''
# æŠ•èµ„ç»„åˆåˆ†æ
total_value = 0
weighted_volatility = 0
sector_counts = {}
risk_levels = {'é«˜é£é™©': 0, 'ä¸­é£é™©': 0, 'ä½é£é™©': 0}

for stock in holdings:
    value = stock['shares'] * stock['price']
    volatility = stock.get('volatility', 0.5)
    sector = stock.get('sector', 'å…¶ä»–')
    
    total_value = total_value + value
    weighted_volatility = weighted_volatility + value * volatility
    
    # ç»Ÿè®¡è¡Œä¸š
    if sector in sector_counts:
        sector_counts[sector] = sector_counts[sector] + 1
    else:
        sector_counts[sector] = 1
    
    # é£é™©åˆ†çº§
    if volatility > 0.7:
        risk_levels['é«˜é£é™©'] = risk_levels['é«˜é£é™©'] + value
    elif volatility > 0.4:
        risk_levels['ä¸­é£é™©'] = risk_levels['ä¸­é£é™©'] + value
    else:
        risk_levels['ä½é£é™©'] = risk_levels['ä½é£é™©'] + value

avg_volatility = weighted_volatility / total_value if total_value > 0 else 0

if avg_volatility > 0.6:
    overall_risk = 'é«˜é£é™©'
elif avg_volatility > 0.3:
    overall_risk = 'ä¸­é£é™©'
else:
    overall_risk = 'ä½é£é™©'

{
    'total_value': total_value,
    'avg_volatility': avg_volatility,
    'overall_risk': overall_risk,
    'risk_distribution': risk_levels,
    'sector_distribution': sector_counts,
    'stock_count': len(holdings)
}
'''
        return self.analyze(code, {'holdings': holdings}, description="æŠ•èµ„ç»„åˆé£é™©è¯„ä¼°")
    
    def detect_anomalies(self, data: List[Dict], threshold: float = 0.05) -> Dict[str, Any]:
        """
        å¼‚å¸¸æ£€æµ‹
        ç”¨äº: ä¾›åº”å•†ç›‘æ§ã€ä»·æ ¼ç›‘æ§
        """
        code = '''
# å¼‚å¸¸æ£€æµ‹
anomalies = []
changes = []

for item in data:
    change = item['change_pct']
    changes.append(change)
    
    if abs(change) > threshold:
        direction = 'å¤§æ¶¨' if change > 0 else 'å¤§è·Œ'
        anomalies.append({
            'name': item['name'],
            'change_pct': change,
            'direction': direction
        })

# è®¡ç®—ç»Ÿè®¡æ•°æ®
if changes:
    total_change = 0
    max_change = changes[0]
    min_change = changes[0]
    
    for c in changes:
        total_change = total_change + c
        if c > max_change:
            max_change = c
        if c < min_change:
            min_change = c
    
    avg_change = total_change / len(changes)
else:
    avg_change = 0
    max_change = 0
    min_change = 0

{
    'anomalies': anomalies,
    'anomaly_count': len(anomalies),
    'avg_change': avg_change,
    'max_change': max_change,
    'min_change': min_change,
    'threshold': threshold
}
'''
        return self.analyze(code, {'data': data, 'threshold': threshold}, 
                          description=f"å¼‚å¸¸æ£€æµ‹ (é˜ˆå€¼: {threshold})")
    
    def summarize_texts(self, texts: List[str], max_length: int = 100) -> Dict[str, Any]:
        """
        æ–‡æœ¬æ‘˜è¦ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
        ç”¨äº: æ¨æ–‡æ±‡æ€»ã€æ–°é—»æ‘˜è¦
        """
        code = '''
# æ–‡æœ¬æ‘˜è¦
all_text = ' '.join(texts)
words = all_text.split()

# ç»Ÿè®¡è¯é¢‘
word_counts = {}
for word in words:
    word = word.lower()
    # ç®€å•è¿‡æ»¤
    if len(word) > 3 and word not in ['the', 'and', 'for', 'with', 'this', 'that']:
        if word in word_counts:
            word_counts[word] = word_counts[word] + 1
        else:
            word_counts[word] = 1

# æ‰¾å‡ºé«˜é¢‘è¯
top_words = []
for word, count in word_counts.items():
    if count > 1:
        top_words.append((word, count))

# ç®€å•æ’åºï¼ˆå†’æ³¡ï¼‰
for i in range(len(top_words)):
    for j in range(i + 1, len(top_words)):
        if top_words[j][1] > top_words[i][1]:
            temp = top_words[i]
            top_words[i] = top_words[j]
            top_words[j] = temp

# å–å‰5
keywords = []
for i in range(min(5, len(top_words))):
    keywords.append(top_words[i][0])

{
    'total_texts': len(texts),
    'total_words': len(words),
    'unique_words': len(word_counts),
    'keywords': keywords,
    'avg_length': len(all_text) / len(texts) if texts else 0
}
'''
        return self.analyze(code, {'texts': texts}, description="æ–‡æœ¬æ‘˜è¦åˆ†æ")
    
    def get_log(self, n: int = 10) -> List[Dict]:
        """è·å–æœ€è¿‘çš„æ‰§è¡Œæ—¥å¿—"""
        return self.execution_log[-n:]
    
    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.execution_log = []


# ==================== ä¾¿æ·å‡½æ•° ====================

_analyzer = MontyAnalyzer()

def analyze_tokens(tokens: List[Dict]) -> Dict:
    """åˆ†æ Meme å¸"""
    return _analyzer.analyze_tokens(tokens)

def analyze_sentiment(text: str) -> Dict:
    """æƒ…ç»ªåˆ†æ"""
    return _analyzer.analyze_sentiment(text)

def analyze_portfolio(holdings: List[Dict]) -> Dict:
    """æŠ•èµ„ç»„åˆåˆ†æ"""
    return _analyzer.analyze_portfolio(holdings)

def detect_anomalies(data: List[Dict], threshold: float = 0.05) -> Dict:
    """å¼‚å¸¸æ£€æµ‹"""
    return _analyzer.detect_anomalies(data, threshold)

def summarize_texts(texts: List[str]) -> Dict:
    """æ–‡æœ¬æ‘˜è¦"""
    return _analyzer.summarize_texts(texts)


# ==================== æµ‹è¯• ====================

if __name__ == "__main__":
    print("ğŸ§  Monty Analyzer æµ‹è¯•\n")
    
    analyzer = MontyAnalyzer()
    
    # æµ‹è¯•1: Meme å¸åˆ†æ
    print("=" * 50)
    print("æµ‹è¯•1: Meme å¸åˆ†æ")
    print("=" * 50)
    tokens = [
        {'symbol': 'CMP', 'holders': 245, 'mc': 20000, 'narrative': 'æ•æ„Ÿ/äº‰è®®'},
        {'symbol': 'INU', 'holders': 206, 'mc': 21000, 'narrative': 'åŠ¨ç‰©+é‡‘è'},
        {'symbol': 'DIGLETT', 'holders': 181, 'mc': 22000, 'narrative': 'æ¸¸æˆ/åŠ¨æ¼«'},
    ]
    result = analyzer.analyze_tokens(tokens)
    print(f"âœ… æ‰§è¡Œæ—¶é—´: {result['execution_time_ms']:.3f} ms")
    print(f"ç»“æœ: {json.dumps(result['result'], indent=2, ensure_ascii=False)}")
    print()
    
    # æµ‹è¯•2: æƒ…ç»ªåˆ†æ
    print("=" * 50)
    print("æµ‹è¯•2: æƒ…ç»ªåˆ†æ")
    print("=" * 50)
    tweet = "This is an amazing project! Love the bullish trend to the moon!"
    result = analyzer.analyze_sentiment(tweet)
    print(f"æ¨æ–‡: {tweet}")
    print(f"âœ… æ‰§è¡Œæ—¶é—´: {result['execution_time_ms']:.3f} ms")
    print(f"ç»“æœ: {result['result']}")
    print()
    
    # æµ‹è¯•3: å¼‚å¸¸æ£€æµ‹
    print("=" * 50)
    print("æµ‹è¯•3: å¼‚å¸¸æ£€æµ‹")
    print("=" * 50)
    data = [
        {'name': 'ä¸­å›½é“ä¸š', 'change_pct': 0.02},
        {'name': 'è“æ™“ç§‘æŠ€', 'change_pct': 0.08},
        {'name': 'åŒ—æ–¹ååˆ›', 'change_pct': -0.06},
        {'name': 'ä¸­å¾®å…¬å¸', 'change_pct': 0.01},
    ]
    result = analyzer.detect_anomalies(data, threshold=0.05)
    print(f"âœ… æ‰§è¡Œæ—¶é—´: {result['execution_time_ms']:.3f} ms")
    print(f"å¼‚å¸¸æ•°: {result['result']['anomaly_count']}")
    print(f"å¼‚å¸¸é¡¹: {result['result']['anomalies']}")
    print()
    
    print("=" * 50)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 50)
    print(f"\næ‰§è¡Œæ—¥å¿—: {len(analyzer.execution_log)} æ¡è®°å½•")
