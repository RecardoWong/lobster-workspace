#!/usr/bin/env python3
"""
ğŸš€ Elon Musk æ¨æ–‡å†…å®¹åˆ†æç³»ç»Ÿï¼ˆæç®€ç‰ˆï¼‰
æ—©æ™šä¸¤æ¬¡æŠ¥å‘Šï¼ˆ08:00 & 21:00ï¼‰
åªå±•ç¤ºæ¨æ–‡å†…å®¹åˆ†ç±»ï¼Œæ— æ•°æ®ã€æ— æŠ•èµ„å»ºè®®
"""

import json
from datetime import datetime
from typing import List, Dict

class ElonContentAnalyzer:
    """Elonå†…å®¹åˆ†æå¸ˆ - æç®€ç‰ˆ"""
    
    def __init__(self):
        # ç§»é™¤Dogecoinï¼Œåªä¿ç•™æ ¸å¿ƒäº§ä¸š
        self.industries = {
            'tesla': {
                'name': 'ğŸš— Tesla',
                'keywords': ['tesla', 'tsla', 'cybertruck', 'autopilot', 'fsd', 'model s', 'model 3', 'model x', 'model y'],
                'focus': 'ç”µåŠ¨è½¦äº§å“ã€è‡ªåŠ¨é©¾é©¶æŠ€æœ¯ã€å·¥å‚äº§èƒ½'
            },
            'spacex': {
                'name': 'ğŸš€ SpaceX',
                'keywords': ['spacex', 'starship', 'falcon', 'starlink', 'mars', 'rocket', 'launch'],
                'focus': 'æ˜Ÿèˆ°è¯•é£ã€æ˜Ÿé“¾æœåŠ¡ã€å¤ªç©ºä»»åŠ¡'
            },
            'xai': {
                'name': 'ğŸ¤– xAI',
                'keywords': ['xai', 'grok', 'ai', 'artificial intelligence', 'agi'],
                'focus': 'AIæŠ€æœ¯ã€Grokäº§å“ã€ç ”å‘è¿›å±•'
            },
            'twitter': {
                'name': 'ğŸ¦ X',
                'keywords': ['x', 'twitter', 'tweet', 'platform'],
                'focus': 'å¹³å°åŠŸèƒ½ã€å†…å®¹æ”¿ç­–ã€äº§å“æ›´æ–°'
            },
            'neuralink': {
                'name': 'ğŸ§  Neuralink',
                'keywords': ['neuralink', 'brain', 'neural'],
                'focus': 'è„‘æœºæ¥å£ã€ä¸´åºŠè¯•éªŒã€æŠ€æœ¯çªç ´'
            },
            'boring': {
                'name': 'ğŸš‡ Boring',
                'keywords': ['boring', 'tunnel', 'hyperloop'],
                'focus': 'éš§é“å·¥ç¨‹ã€äº¤é€šé¡¹ç›®'
            },
            'other': {
                'name': 'ğŸ“ å…¶ä»–',
                'keywords': [],
                'focus': 'ä¸ªäººåŠ¨æ€ã€ç¤¾ä¼šè¯é¢˜ã€å…¶ä»–å†…å®¹'
            }
        }
    
    def analyze_content(self, text: str) -> List[str]:
        """åˆ†ææ¨æ–‡å†…å®¹æ¶‰åŠçš„äº§ä¸š"""
        if not text:
            return ['other']
        
        text_lower = text.lower()
        matched = []
        
        for ind_id, info in self.industries.items():
            if ind_id == 'other':
                continue
            for keyword in info['keywords']:
                if keyword in text_lower:
                    matched.append(ind_id)
                    break
        
        return matched if matched else ['other']
    
    def clean_text(self, text: str) -> str:
        """æ¸…ç†æ¨æ–‡å†…å®¹"""
        # å»é™¤é“¾æ¥
        text = text.split('http')[0]
        # å»é™¤@mention
        words = text.split()
        clean_words = [w for w in words if not w.startswith('@')]
        return ' '.join(clean_words).strip()
    
    def generate_report(self, tweets: List[Dict]) -> str:
        """ç”Ÿæˆæç®€å†…å®¹æŠ¥å‘Š"""
        now = datetime.now()
        period = "æ—©å ±" if now.hour < 12 else "æ™šå ±"
        
        lines = [
            f"ğŸš€ Elon Musk | {period}",
            f"ğŸ“… {now.strftime('%mæœˆ%dæ—¥')}",
            "=" * 40,
            ""
        ]
        
        if not tweets:
            lines.append("ğŸ“­ æœ¬æ—¶æ®µæ— æ–°æ¨æ–‡")
            return "\n".join(lines)
        
        # æŒ‰äº§ä¸šåˆ†ç±»
        industry_content = {ind_id: [] for ind_id in self.industries.keys()}
        
        for tweet in tweets:
            text = tweet.get('text', '').strip()
            if not text:
                continue
            
            industries = self.analyze_content(text)
            clean = self.clean_text(text)
            
            if clean:
                for ind_id in industries:
                    if clean not in industry_content[ind_id]:
                        industry_content[ind_id].append(clean)
        
        # ç”ŸæˆæŠ¥å‘Š - æŒ‰ä¼˜å…ˆçº§
        has_content = False
        priority = ['tesla', 'spacex', 'xai', 'twitter', 'neuralink', 'boring', 'other']
        
        for ind_id in priority:
            contents = industry_content.get(ind_id, [])
            if not contents:
                continue
            
            has_content = True
            info = self.industries[ind_id]
            
            # äº§ä¸šæ ‡é¢˜
            lines.append(f"\n{info['name']} | {info['focus']}")
            lines.append("â”€" * 40)
            
            # åˆ—å‡ºå†…å®¹ï¼ˆå»é‡ï¼Œæœ€å¤š3æ¡ï¼‰
            for content in contents[:3]:
                lines.append(f"â€¢ {content[:100]}")
        
        if not has_content:
            lines.append("\nğŸ“­ æœ¬æ—¶æ®µæ— ç›¸å…³å†…å®¹")
        
        lines.append("\n" + "=" * 40)
        
        return "\n".join(lines)


def main():
    """ä¸»å‡½æ•°"""
    analyzer = ElonContentAnalyzer()
    
    # æ¨¡æ‹Ÿæ•°æ®
    sample = [
        {'text': 'Tesla FSD v12 is amazing!'},
        {'text': 'Starship launch next week'},
        {'text': 'Grok is learning fast'},
        {'text': 'Great progress at xAI'},
    ]
    
    print(analyzer.generate_report(sample))


if __name__ == "__main__":
    main()
