#!/usr/bin/env python3
"""
Memeå¸å®æ—¶ç›‘æ§ç³»ç»Ÿ v3.0 - æ¼”ç¤ºç‰ˆ
æ¯å°æ—¶æ‰«æBaseé“¾ï¼Œæä¾›åŸå› åˆ†æå’Œçƒ­ç‚¹è¯†åˆ«
"""

import urllib.request
import json
import random
from datetime import datetime
from typing import Dict, List, Optional

class BaseMemeMonitor:
    """Baseé“¾Memeå¸ç›‘æ§å™¨"""
    
    def __init__(self):
        self.hotspots = []
        self.signals = []
    
    def get_base_hot_tokens(self) -> List[Dict]:
        """è·å–Baseé“¾çƒ­é—¨ä»£å¸"""
        print("ğŸ” æ­£åœ¨æ‰«æBaseé“¾...")
        
        try:
            # ä½¿ç”¨DexScreener search APIè·å–Baseé“¾ä»£å¸
            url = "https://api.dexscreener.com/latest/dex/search?q=base%20chain"
            
            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, timeout=15) as resp:
                data = json.loads(resp.read().decode('utf-8'))
                pairs = data.get('pairs', [])
                
                # ç­›é€‰Baseé“¾ä¸”ç¬¦åˆæ¡ä»¶çš„ä»£å¸
                filtered = []
                seen_symbols = set()
                
                for pair in pairs:
                    chain = pair.get('chainId', '').lower()
                    if chain != 'base':
                        continue
                    
                    symbol = pair.get('baseToken', {}).get('symbol', '???')
                    if symbol in seen_symbols or symbol == '???':
                        continue
                    seen_symbols.add(symbol)
                    
                    liquidity = float(pair.get('liquidity', {}).get('usd', 0) or 0)
                    volume_24h = float(pair.get('volume', {}).get('h24', 0) or 0)
                    price_change = float(pair.get('priceChange', {}).get('h24', 0) or 0)
                    
                    # åªç›‘æ§Clankerå‘å¸ƒçš„å¸
                    # Clankeræ˜¯OpenClawçš„Token Factoryï¼ŒBaseé“¾AI Agent Launchpad
                    # CLANKERåˆçº¦: 0x1bc0...6d1bcb
                    CLANKER_KEYWORDS = ['clanker', 'claw', 'ai', 'agent', 'bot', 'bankr', 'aixbt', 'luna', 'zerebro']
                    
                    symbol_lower = symbol.lower()
                    name_lower = pair.get('baseToken', {}).get('name', '').lower()
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºClankerç”Ÿæ€å¸
                    is_clanker = any(keyword in symbol_lower or keyword in name_lower 
                                     for keyword in CLANKER_KEYWORDS)
                    
                    # åŒæ—¶éœ€è¦æ˜¯Memeå¸è§„æ¨¡ï¼ˆæ’é™¤è¶…å¤§å¸‚å€¼ï¼‰
                    is_meme_size = 10000 < liquidity < 100000000  # $10K - $100M
                    
                    if is_clanker and is_meme_size:
                        address = pair.get('baseToken', {}).get('address', '')
                        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°åˆçº¦
                        is_new = self.db.is_new(address)
                        # æ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²å‡ºç°è¿‡
                        today = datetime.now().strftime('%Y-%m-%d')
                        appears_today = False
                        if address.lower() in self.db.contract_history:
                            first_seen = self.db.contract_history[address.lower()].get('first_seen', '')
                            appears_today = today in first_seen or (datetime.now() - datetime.fromisoformat(first_seen.replace('Z', '+00:00'))).days == 0
                        
                        filtered.append({
                            'name': pair.get('baseToken', {}).get('name', 'Unknown'),
                            'symbol': symbol,
                            'address': address,
                            'price': float(pair.get('priceUsd', 0) or 0),
                            'liquidity': liquidity,
                            'volume_24h': volume_24h,
                            'change_24h': price_change,
                            'tx_count': (pair.get('txns', {}).get('h24', {}).get('buys', 0) or 0) + 
                                       (pair.get('txns', {}).get('h24', {}).get('sells', 0) or 0),
                            'pair_url': pair.get('url', ''),
                            'is_new': is_new,
                            'appears_today': appears_today
                        })
                        
                        # æ–°åˆçº¦æ·»åŠ åˆ°æ•°æ®åº“
                        if is_new:
                            self.db.add(address, {
                                'name': pair.get('baseToken', {}).get('name', 'Unknown'),
                                'symbol': symbol,
                                'first_seen_price': float(pair.get('priceUsd', 0) or 0)
                            })
                
                # æŒ‰äº¤æ˜“é‡æ’åº
                filtered.sort(key=lambda x: x['volume_24h'], reverse=True)
                print(f"âœ… æ‰¾åˆ° {len(filtered)} ä¸ªç¬¦åˆæ¡ä»¶çš„Memeå¸")
                return filtered[:10]
                
        except Exception as e:
            print(f"âŒ è·å–æ•°æ®å¤±è´¥: {e}")
            # è¿”å›æ¼”ç¤ºæ•°æ®
            return self._generate_demo_data()
    
    def _generate_demo_data(self) -> List[Dict]:
        """ç”Ÿæˆæ¼”ç¤ºæ•°æ®"""
        print("âš ï¸ ä½¿ç”¨æ¼”ç¤ºæ•°æ®...")
        demo_tokens = [
            {'name': 'PepeBase', 'symbol': 'PEPEB', 'price': 0.00001234, 'liquidity': 150000, 'volume_24h': 85000, 'change_24h': 125.5, 'tx_count': 450, 'pair_url': 'https://dexscreener.com/base/0x123'},
            {'name': 'BaseDoge', 'symbol': 'BDOGE', 'price': 0.0005678, 'liquidity': 89000, 'volume_24h': 45000, 'change_24h': 45.2, 'tx_count': 320, 'pair_url': 'https://dexscreener.com/base/0x456'},
            {'name': 'MoonBase', 'symbol': 'MOON', 'price': 0.001234, 'liquidity': 67000, 'volume_24h': 23000, 'change_24h': -15.8, 'tx_count': 180, 'pair_url': 'https://dexscreener.com/base/0x789'},
            {'name': 'BaseAI', 'symbol': 'BAI', 'price': 0.002345, 'liquidity': 45000, 'volume_24h': 12000, 'change_24h': 78.9, 'tx_count': 95, 'pair_url': 'https://dexscreener.com/base/0xabc'},
        ]
        return demo_tokens
    
    def analyze_reason(self, token: Dict) -> str:
        """åˆ†ææ¶¨è·ŒåŸå› """
        reasons = []
        change = token.get('change_24h', 0)
        volume = token.get('volume_24h', 0)
        liquidity = token.get('liquidity', 0)
        tx_count = token.get('tx_count', 0)
        
        # ä»·æ ¼åŸå› 
        if change > 100:
            reasons.append("ğŸš€ è¶…çº§æš´æ¶¨(100%+)ï¼Œå¯èƒ½é‡å¤§åˆ©å¥½/ä¸Šæ‰€")
        elif change > 50:
            reasons.append("ğŸŒ™ æš´æ¶¨(50%+)ï¼Œç¤¾åŒºFOMOæƒ…ç»ªä¸¥é‡")
        elif change > 20:
            reasons.append("ğŸ“ˆ å¤§å¹…ä¸Šæ¶¨(20%+)ï¼Œä¹°ç›˜å¼ºåŠ²")
        elif change > 0:
            reasons.append("ğŸ’¹ ç¨³æ­¥ä¸Šæ¶¨ï¼Œè¶‹åŠ¿è‰¯å¥½")
        elif change > -20:
            reasons.append("ğŸ“Š æ­£å¸¸å›è°ƒ")
        else:
            reasons.append("ğŸ’¥ æš´è·Œ(-20%+)ï¼Œå¯èƒ½rug pull/ææ…ŒæŠ›å”®")
        
        # äº¤æ˜“é‡åŸå› 
        volume_ratio = volume / liquidity if liquidity > 0 else 0
        if volume_ratio > 2:
            reasons.append(f"ğŸ”¥ é«˜æ¢æ‰‹ç‡({volume_ratio:.1f}x)ï¼Œæåº¦æ´»è·ƒ")
        elif volume_ratio > 0.5:
            reasons.append(f"âš¡ äº¤æ˜“æ´»è·ƒ(æ¢æ‰‹ç‡{volume_ratio:.1f}x)")
        else:
            reasons.append(f"ğŸ’¤ äº¤æ˜“æ¸…æ·¡(æ¢æ‰‹ç‡{volume_ratio:.1f}x)")
        
        # äº¤æ˜“ç¬”æ•°
        if tx_count > 300:
            reasons.append(f"ğŸ‘¥ å¤§é‡æ•£æˆ·å‚ä¸({tx_count}ç¬”)")
        elif tx_count > 100:
            reasons.append(f"ğŸ‘¤ ç¤¾åŒºæ´»è·ƒ({tx_count}ç¬”)")
        
        return " | ".join(reasons)
    
    def identify_hotspots(self, tokens: List[Dict]) -> Dict:
        """è¯†åˆ«å¸‚åœºçƒ­ç‚¹"""
        if not tokens:
            return {}
        
        hotspots = {
            'market_sentiment': '',
            'top_gainers': [],
            'top_volume': [],
            'hot_narratives': []
        }
        
        # è®¡ç®—å¹³å‡æ¶¨è·Œå¹…
        avg_change = sum(t.get('change_24h', 0) for t in tokens) / len(tokens)
        total_volume = sum(t.get('volume_24h', 0) for t in tokens)
        
        # å¸‚åœºæƒ…ç»ª
        if avg_change > 50:
            hotspots['market_sentiment'] = "ğŸ”¥ğŸ”¥ğŸ”¥ æåº¦ç‹‚çƒ­ - Baseé“¾memeå¸å…¨é¢çˆ†å‘ï¼å¹³å‡æ¶¨å¹…" + f"{avg_change:.0f}%"
        elif avg_change > 20:
            hotspots['market_sentiment'] = "ğŸ”¥ğŸ”¥ éå¸¸ç«çƒ­ - Baseé“¾memeå¸æ•´ä½“ä¸Šæ¶¨ï¼Œå¹³å‡æ¶¨å¹…" + f"{avg_change:.0f}%"
        elif avg_change > 0:
            hotspots['market_sentiment'] = "ğŸ”¥ æ¸©å’Œä¸Šæ¶¨ - Baseé“¾memeå¸æƒ…ç»ªç§¯æï¼Œå¹³å‡æ¶¨å¹…" + f"{avg_change:.0f}%"
        elif avg_change > -20:
            hotspots['market_sentiment'] = "ğŸ“Š æ¨ªç›˜æ•´ç† - Baseé“¾memeå¸æƒ…ç»ªä¸­æ€§ï¼Œå¹³å‡è·Œå¹…" + f"{abs(avg_change):.0f}%"
        else:
            hotspots['market_sentiment'] = "â„ï¸ æ•´ä½“å›è°ƒ - Baseé“¾memeå¸å†·å´ï¼Œå¹³å‡è·Œå¹…" + f"{abs(avg_change):.0f}%"
        
        # æ¶¨å¹…æ¦œTOP3
        sorted_by_change = sorted(tokens, key=lambda x: x.get('change_24h', 0), reverse=True)
        hotspots['top_gainers'] = sorted_by_change[:3]
        
        # äº¤æ˜“é‡æ¦œTOP3
        sorted_by_volume = sorted(tokens, key=lambda x: x.get('volume_24h', 0), reverse=True)
        hotspots['top_volume'] = sorted_by_volume[:3]
        
        # è¯†åˆ«çƒ­é—¨å™äº‹
        hot_symbols = [t['symbol'] for t in sorted_by_change[:5]]
        if any('PEPE' in s or 'DOGE' in s for s in hot_symbols):
            hotspots['hot_narratives'].append("ğŸ¸ Memeæ–‡åŒ–å¸çƒ­åº¦é«˜")
        if any('AI' in s or 'GPT' in s for s in hot_symbols):
            hotspots['hot_narratives'].append("ğŸ¤– AIæ¦‚å¿µå¸å—è¿½æ§")
        if any(t.get('change_24h', 0) > 100 for t in tokens):
            hotspots['hot_narratives'].append("ğŸš€ å¤šä¸ªå¸æš´æ¶¨100%+ï¼Œå¸‚åœºæåº¦FOMO")
        
        return hotspots
    
    def generate_signal(self, token: Dict) -> Optional[Dict]:
        """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
        score = 0
        reasons = []
        signal_type = "HOLD"
        
        change = token.get('change_24h', 0)
        volume = token.get('volume_24h', 0)
        liquidity = token.get('liquidity', 0)
        
        # æµåŠ¨æ€§è¯„åˆ†
        if liquidity > 100000:
            score += 30
            reasons.append("ğŸ’° æµåŠ¨æ€§ä¼˜ç§€")
        elif liquidity > 50000:
            score += 20
            reasons.append("ğŸ’§ æµåŠ¨æ€§è‰¯å¥½")
        elif liquidity > 10000:
            score += 10
            reasons.append("âš ï¸ æµåŠ¨æ€§ä¸€èˆ¬")
        
        # äº¤æ˜“é‡è¯„åˆ†
        volume_ratio = volume / liquidity if liquidity > 0 else 0
        if volume_ratio > 1:
            score += 25
            reasons.append("ğŸ”¥ äº¤æ˜“æåº¦æ´»è·ƒ")
        elif volume_ratio > 0.3:
            score += 15
            reasons.append("âš¡ äº¤æ˜“æ´»è·ƒ")
        
        # ä»·æ ¼è¶‹åŠ¿è¯„åˆ†
        if 20 < change < 100:
            score += 20
            reasons.append("ğŸ“ˆ å¥åº·ä¸Šæ¶¨")
        elif change > 100:
            score += 5
            reasons.append("ğŸš€ æš´æ¶¨(é«˜é£é™©)")
        elif change < -30:
            score -= 20
            reasons.append("ğŸ“‰ å¤§å¹…å›è°ƒ")
        
        # ä¿¡å·åˆ¤å®š
        if score >= 60:
            signal_type = "ğŸŸ¢ STRONG_BUY"
        elif score >= 40:
            signal_type = "ğŸŸ¡ BUY"
        elif score >= 25:
            signal_type = "ğŸŸ  WATCH"
        else:
            signal_type = "âšª SKIP"
        
        if score >= 40:
            return {
                'symbol': token['symbol'],
                'score': score,
                'signal': signal_type,
                'reasons': reasons,
                'price': token['price'],
                'change': change
            }
        return None
    
    def generate_report(self) -> str:
        """ç”Ÿæˆå®Œæ•´ç›‘æ§æŠ¥å‘Š"""
        tokens = self.get_base_hot_tokens()
        
        if not tokens:
            return "âš ï¸ æœªèƒ½è·å–æ•°æ®"
        
        lines = [
            "="*70,
            "ğŸš€ Baseé“¾Memeå¸å®æ—¶ç›‘æ§æŠ¥å‘Š",
            f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "="*70,
            ""
        ]
        
        # çƒ­ç‚¹è¯†åˆ«
        hotspots = self.identify_hotspots(tokens)
        lines.extend([
            "ğŸ”¥ å¸‚åœºçƒ­ç‚¹",
            "-"*70,
            f"{hotspots.get('market_sentiment', '')}",
            ""
        ])
        
        # æ¶¨å¹…æ¦œ
        if hotspots.get('top_gainers'):
            lines.extend([
                "ğŸ“ˆ æ¶¨å¹…æ¦œTOP3",
                "-"*70
            ])
            for i, t in enumerate(hotspots['top_gainers'][:3], 1):
                emoji = "ğŸ¥‡" if i==1 else "ğŸ¥ˆ" if i==2 else "ğŸ¥‰"
                lines.append(f"{emoji} {t['symbol']}: {t['change_24h']:+.2f}% | ğŸ’§${t['liquidity']:,.0f} | ğŸ“Š${t['volume_24h']:,.0f}")
            lines.append("")
        
        # äº¤æ˜“é‡æ¦œ
        if hotspots.get('top_volume'):
            lines.extend([
                "ğŸ’§ äº¤æ˜“é‡æ¦œTOP3",
                "-"*70
            ])
            for i, t in enumerate(hotspots['top_volume'][:3], 1):
                lines.append(f"{i}. {t['symbol']}: ${t['volume_24h']:,.0f} | {t['change_24h']:+.2f}%")
            lines.append("")
        
        # çƒ­é—¨å™äº‹
        if hotspots.get('hot_narratives'):
            lines.extend([
                "ğŸ¯ çƒ­é—¨å™äº‹",
                "-"*70
            ])
            for narrative in hotspots['hot_narratives']:
                lines.append(f"  {narrative}")
            lines.append("")
        
        # è¯¦ç»†ä»£å¸åˆ†æ
        lines.extend([
            "="*70,
            "ğŸ“‹ è¯¦ç»†Memeå¸åˆ†æ (å™äº‹ + ç«çˆ†åŸå› )",
            "="*70,
            ""
        ])
        
        for i, token in enumerate(tokens[:5], 1):
            # æ ‡è®°çŠ¶æ€
            status_mark = ""
            if token.get('is_new'):
                status_mark = " ğŸ†•ã€é¦–æ¬¡å‡ºç°ã€‘"
            elif token.get('appears_today'):
                status_mark = " ğŸ”ã€ä»Šæ—¥å¤šæ¬¡ã€‘"
            
            lines.extend([
                f"\n{'â”€'*70}",
                f"#{i} {token['symbol']}{status_mark}",
                f"{'â”€'*70}",
                f"ğŸ’° ä»·æ ¼: ${token['price']:.8f} | 24h: {token['change_24h']:+.2f}%",
                f"ğŸ’§ æµåŠ¨æ€§: ${token['liquidity']:,.0f} | äº¤æ˜“é‡: ${token['volume_24h']:,.0f}",
                f"ğŸ”„ äº¤æ˜“ç¬”æ•°: {token.get('tx_count', 0)}",
                ""
            ])
            
            # åˆçº¦åœ°å€ï¼ˆæ–°åˆçº¦æ˜¾ç¤ºå®Œæ•´åœ°å€ï¼‰
            if token.get('is_new'):
                lines.append(f"ğŸ“„ åˆçº¦: {token['address']}")
                lines.append("")
            
            # åŸå› åˆ†æ
            reason = self.analyze_reason(token)
            lines.append(f"ğŸ’¡ åŸå› : {reason}")
            
            lines.append(f"\nğŸ”— DexScreener: {token.get('pair_url', 'N/A')}")
        
        lines.extend([
            "",
            "âš ï¸ é£é™©æç¤º: Memeå¸é«˜é£é™©ï¼Œä»¥ä¸Šä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„éœ€è°¨æ…",
            "="*70
        ])
        
        return "\n".join(lines)


def main():
    """ä¸»å‡½æ•°"""
    monitor = BaseMemeMonitor()
    report = monitor.generate_report()
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    filename = f"/tmp/meme_monitor_{datetime.now().strftime('%Y%m%d_%H%M')}.txt"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {filename}")


if __name__ == "__main__":
    main()
