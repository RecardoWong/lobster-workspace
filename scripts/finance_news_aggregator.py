#!/usr/bin/env python3
"""
è´¢ç»æ–°é—»èšåˆå™¨
æ•´åˆï¼šæ™ºé€šè´¢ç»ã€æ–°æµªè´¢ç»ã€è´¢è”ç¤¾
"""

import requests
import json
import re
from datetime import datetime, timedelta
from pathlib import Path

class NewsAggregator:
    def __init__(self):
        self.output_file = '/root/.openclaw/workspace/lobster-workspace/dashboard/data/finance_news.json'
        self.news_list = []
        
    def fetch_zhitong(self):
        """è·å–æ™ºé€šè´¢ç»æ–°é—»"""
        try:
            url = 'https://www.zhitongcaijing.com/content/recommend.html'
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            
            # æå–æ–°é—»
            news_items = []
            # ç®€å•æ­£åˆ™æå–æ ‡é¢˜å’Œé“¾æ¥
            pattern = r'<a[^>]*href="([^"]*\/detail\/[^"]*)"[^>]*>\s*<[^>]*>\s*([^<]{10,})'
            matches = re.findall(pattern, response.text)
            
            for i, (link, title) in enumerate(matches[:5]):
                if 'zhitongcaijing.com' not in link:
                    link = 'https://www.zhitongcaijing.com' + link
                news_items.append({
                    'title': title.strip(),
                    'source': 'æ™ºé€šè´¢ç»',
                    'url': link,
                    'time': f'{i+1}å°æ—¶å‰',
                    'tag': 'æ¸¯è‚¡',
                    'tagColor': '#3b82f6'
                })
            
            print(f'âœ… æ™ºé€šè´¢ç»: {len(news_items)} æ¡')
            return news_items
        except Exception as e:
            print(f'âŒ æ™ºé€šè´¢ç»è·å–å¤±è´¥: {str(e)[:50]}')
            return []
    
    def fetch_sina_finance(self):
        """è·å–æ–°æµªè´¢ç»æ–°é—»"""
        try:
            # æ–°æµªè´¢ç»API
            url = 'https://feed.sina.com.cn/api/roll/get?pageid=153&lid=2516&k=&num=10&page=1&r=0.5'
            response = requests.get(url, timeout=10)
            data = response.json()
            
            news_items = []
            if 'result' in data and 'data' in data['result']:
                for item in data['result']['data'][:5]:
                    news_items.append({
                        'title': item.get('title', ''),
                        'source': 'æ–°æµªè´¢ç»',
                        'url': item.get('url', ''),
                        'time': 'åˆšåˆš',
                        'tag': 'è´¢ç»',
                        'tagColor': '#ef4444'
                    })
            
            print(f'âœ… æ–°æµªè´¢ç»: {len(news_items)} æ¡')
            return news_items
        except Exception as e:
            print(f'âŒ æ–°æµªè´¢ç»è·å–å¤±è´¥: {str(e)[:50]}')
            return []
    
    def fetch_cls(self):
        """è·å–è´¢è”ç¤¾æ–°é—»"""
        try:
            # è´¢è”ç¤¾æ»šåŠ¨æ–°é—»
            url = 'https://www.cls.cn/api/roll/get'
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Referer': 'https://www.cls.cn/'
            }
            response = requests.get(url, headers=headers, timeout=10)
            data = response.json()
            
            news_items = []
            if data.get('code') == 200 and 'data' in data:
                for item in data['data'][:5]:
                    news_items.append({
                        'title': item.get('title', ''),
                        'source': 'è´¢è”ç¤¾',
                        'url': f"https://www.cls.cn/detail/{item.get('id', '')}",
                        'time': 'åˆšåˆš',
                        'tag': 'å¿«è®¯',
                        'tagColor': '#10b981'
                    })
            
            print(f'âœ… è´¢è”ç¤¾: {len(news_items)} æ¡')
            return news_items
        except Exception as e:
            print(f'âŒ è´¢è”ç¤¾è·å–å¤±è´¥: {str(e)[:50]}')
            return []
    
    def aggregate(self):
        """èšåˆæ‰€æœ‰æ–°é—»"""
        print(f'\nğŸš€ å¼€å§‹æŠ“å–è´¢ç»æ–°é—»... {datetime.now().strftime("%Y-%m-%d %H:%M")}')
        print('=' * 60)
        
        # è·å–å„æºæ–°é—»
        zhitong_news = self.fetch_zhitong()
        sina_news = self.fetch_sina_finance()
        cls_news = self.fetch_cls()
        
        # åˆå¹¶å¹¶å»é‡
        all_news = []
        seen_titles = set()
        
        for news in zhitong_news + sina_news + cls_news:
            title_key = news['title'][:20]  # å‰20å­—ä½œä¸ºå»é‡key
            if title_key not in seen_titles:
                seen_titles.add(title_key)
                all_news.append(news)
        
        # å–å‰10æ¡
        self.news_list = all_news[:10]
        
        print(f'\nğŸ“Š æ€»è®¡: {len(self.news_list)} æ¡ä¸é‡å¤æ–°é—»')
        return self.news_list
    
    def save(self):
        """ä¿å­˜ä¸ºJSON"""
        output = {
            'update_time': datetime.now().isoformat(),
            'source_count': 3,
            'total_count': len(self.news_list),
            'news': self.news_list
        }
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        Path(self.output_file).parent.mkdir(parents=True, exist_ok=True)
        
        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        print(f'\nğŸ’¾ å·²ä¿å­˜: {self.output_file}')
        return self.output_file

def main():
    aggregator = NewsAggregator()
    aggregator.aggregate()
    aggregator.save()
    print('\nâœ… è´¢ç»æ–°é—»èšåˆå®Œæˆ!')

if __name__ == '__main__':
    main()
