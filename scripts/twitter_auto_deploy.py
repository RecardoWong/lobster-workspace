#!/usr/bin/env python3
"""
Twitter è‡ªåŠ¨ç›‘æ§ + ç¿»è¯‘ + éƒ¨ç½²
æ¯å°æ—¶è‡ªåŠ¨è¿è¡Œï¼Œæ— éœ€äººå·¥å¹²é¢„
"""

import os
import json
import asyncio
import subprocess
import urllib.request
import urllib.parse
import re
from datetime import datetime, timezone, timedelta

def translate_text(text):
    """ç¿»è¯‘æ–‡æœ¬ - ä½¿ç”¨æœ¬åœ° Ollama"""
    if not text:
        return ""
    
    # å¦‚æœå·²ç»æ˜¯ä¸­æ–‡ï¼Œç›´æ¥è¿”å›
    if any('\u4e00' <= char <= '\u9fff' for char in text[:50]):
        return text
    
    # ä½¿ç”¨ Ollama æœ¬åœ°ç¿»è¯‘
    try:
        import urllib.request
        prompt = f"Translate to Chinese (only output translation, no explanation): \"{text[:500]}\""
        data = json.dumps({
            "model": "qwen2.5:0.5b",
            "prompt": prompt,
            "stream": False
        }).encode('utf-8')
        
        req = urllib.request.Request(
            'http://127.0.0.1:11434/api/generate',
            data=data,
            headers={'Content-Type': 'application/json'}
        )
        
        with urllib.request.urlopen(req, timeout=30) as response:
            result = json.loads(response.read().decode('utf-8'))
            translated = result.get('response', '').strip().strip('"').strip("'")
            if translated and translated != text:
                return translated
    except Exception as e:
        print(f"  Ollamaç¿»è¯‘å¤±è´¥: {e}")
    
    # å›é€€ï¼šè¿”å›åŸæ–‡æ‘˜è¦
    return text[:100] + "..." if len(text) > 100 else text

# é…ç½®
MONITOR_ACCOUNTS = {
    'elonmusk': 'Elon Musk',
    'jdhasoptions': 'jdhasoptions', 
    'xiaomucrypto': 'xiaomucrypto',
    'aistocksavvy': 'AI Stock Savvy'
}

SAVE_DIR = '/tmp/twitter_monitor'
DASHBOARD_DATA = '/root/.openclaw/workspace/lobster-workspace/dashboard/data/twitter_translated.json'

def get_time_ago(time_str):
    """è®¡ç®—ç›¸å¯¹æ—¶é—´"""
    try:
        tweet_time = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
        now = datetime.now(timezone.utc)
        diff = now - tweet_time
        if diff.days > 0:
            return f"{diff.days}å¤©å‰"
        hours = diff.seconds // 3600
        if hours > 0:
            return f"{hours}å°æ—¶å‰"
        return "åˆšåˆš"
    except:
        return "æœªçŸ¥"

async def fetch_tweets():
    """è¯»å–æŠ“å–çš„æ•°æ®æ–‡ä»¶"""
    print("ğŸ¦ è¯»å– Twitter æ•°æ®...")
    
    all_tweets = {}
    for username, name in MONITOR_ACCOUNTS.items():
        import glob
        files = glob.glob(f"{SAVE_DIR}/{username}_*.json")
        
        if not files:
            print(f"   âš ï¸ {name}: æ— æ–‡ä»¶")
            continue
        
        # æ‰¾æœ€æ–°ä¸”æœ‰æ•°æ®çš„æ–‡ä»¶
        files.sort(key=os.path.getctime, reverse=True)
        latest = None
        for f in files:
            try:
                with open(f, 'r', encoding='utf-8') as fp:
                    data = json.load(fp)
                if len(data.get('tweets', [])) > 0:
                    latest = f
                    break
            except:
                continue
        
        if not latest:
            print(f"   âš ï¸ {name}: æ— æœ‰æ•ˆæ•°æ®")
            continue
        
        try:
            with open(latest, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            tweets_data = data.get('tweets', [])
            tweets = []
            for item in tweets_data[:3]:
                text = item.get('text', '')
                tweet_id = str(item.get('id', ''))
                tweets.append({
                    'author': username,
                    'name': name,
                    'text': text[:150] + "..." if len(text) > 150 else text,
                    'translate': translate_text(text),
                    'time': item.get('time', ''),
                    'time_ago': get_time_ago(item.get('time', '')),
                    'url': f"https://x.com/{username}/status/{tweet_id}" if tweet_id else f"https://x.com/{username}"
                })
            
            all_tweets[username] = tweets
            print(f"  âœ… {name}: {len(tweets)} æ¡ ({os.path.basename(latest)})")
            
        except Exception as e:
            print(f"  âŒ {name}: {e}")
    
    return all_tweets

def save_and_deploy(tweets_data):
    """ä¿å­˜ JSON å¹¶æ›´æ–° HTML é™æ€åµŒå…¥"""
    now = datetime.now()
    output = {
        'update_time': now.isoformat(),
        'tweets': tweets_data
    }
    
    # ä¿å­˜ JSON
    os.makedirs(os.path.dirname(DASHBOARD_DATA), exist_ok=True)
    with open(DASHBOARD_DATA, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    print(f"âœ… JSON å·²ä¿å­˜")
    
    # ç”Ÿæˆ HTML åµŒå…¥å†…å®¹
    html_content = generate_twitter_html(tweets_data, now)
    
    # æ›´æ–° Dashboard HTML
    update_dashboard_html(html_content, now)
    
    # éƒ¨ç½²åˆ°æœåŠ¡å™¨
    print("ğŸš€ éƒ¨ç½²åˆ°æœåŠ¡å™¨...")
    deploy_dashboard()

def generate_twitter_html(tweets_data, now):
    """ç”Ÿæˆ Twitter HTML åµŒå…¥å†…å®¹ - åªæ˜¾ç¤ºå‰5æ¡+æŸ¥çœ‹æ›´å¤š"""
    # åˆå¹¶æ‰€æœ‰æ¨æ–‡
    all_tweets = []
    for username, tweets in tweets_data.items():
        for tweet in tweets:
            tweet['_author'] = username
            all_tweets.append(tweet)
    
    # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    all_tweets.sort(key=lambda x: x.get('time', ''), reverse=True)
    
    # åªå–å‰5æ¡
    top5 = all_tweets[:5]
    
    html_parts = []
    for i, tweet in enumerate(top5, 1):
        # è½¬ä¹‰ HTML ç‰¹æ®Šå­—ç¬¦
        text = tweet['text'].replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;').replace('"', '&quot;')
        translate = tweet['translate'].replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;').replace('"', '&quot;')
        
        html_parts.append(f"""
<a href="{tweet['url']}" target="_blank" style="text-decoration: none; color: inherit; display: block; margin-bottom: 12px; padding: 12px; border-radius: 8px; transition: background 0.2s; border-left: 3px solid #3b82f6;" class="tweet-link">
<div class="tweet-item" style="cursor: pointer;">
<div class="tweet-author">
<span style="background: #3b82f6; color: white; font-size: 11px; padding: 2px 6px; border-radius: 4px; margin-right: 6px;">#{i}</span>
<span class="tweet-author-name">{tweet['name']}</span>
<span class="tweet-author-handle">@{tweet['author']}</span>
<span class="tweet-time" style="color: #ef4444; font-weight: 500;">{tweet['time_ago']}</span>
</div>
<div class="tweet-text">{text}</div>
<div class="tweet-translate"><span style="color: #3b82f6; font-size: 11px;">[ä¸­æ–‡ç¿»è¯‘]</span> {translate}</div>
<div style="margin-top: 8px; font-size: 11px; color: #9ca3af; text-align: right;">ğŸ”— ç‚¹å‡»æŸ¥çœ‹åŸæ¨æ–‡ â†’</div>
</div>
</a>""")
    
    # æ·»åŠ "æŸ¥çœ‹æ›´å¤š"æŒ‰é’®
    more_link = """
<a href="tweets.html" style="display: block; text-align: center; padding: 12px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; text-decoration: none; border-radius: 8px; font-weight: 500; margin-top: 8px; transition: opacity 0.2s;">
    æŸ¥çœ‹æ›´å¤šæ¨æ–‡ â†’
</a>"""
    html_parts.append(more_link)
    
    return '\n'.join(html_parts)

def update_dashboard_html(twitter_html, now):
    """æ›´æ–° Dashboard HTML æ–‡ä»¶"""
    html_path = '/root/.openclaw/workspace/lobster-workspace/dashboard/index.html'
    
    with open(html_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ›´æ–°æ—¶é—´æ ‡ç­¾
    time_str = now.strftime('%Y-%m-%d %H:%M')
    content = re.sub(
        r'(<span[^>]*id="twitterUpdateTime"[^>]*>)æ›´æ–°äº: [^<]+</span>',
        f'\\g<1>æ›´æ–°äº: {time_str}</span>',
        content
    )
    
    # æ›´æ–° Twitter å†…å®¹åŒºåŸŸ (åœ¨ id="twitterContainer" çš„ div ä¸­)
    pattern = r'(<div[^>]*id="twitterContainer"[^>]*>)[\s\S]*?(</div>\s*</div>\s*<!-- ç¬¬ä¸‰åˆ—)'
    replacement = f'\\g<1>{twitter_html}\\n                        \\g<2>'
    content = re.sub(pattern, replacement, content, count=1)
    
    with open(html_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ… HTML å·²æ›´æ–° ({time_str})")

def deploy_dashboard():
    """éƒ¨ç½² Dashboard"""
    deploy_cmd = """
    cd /root/.openclaw/workspace/lobster-workspace/dashboard && 
    scp -i /root/.ssh/lobster_deploy -o StrictHostKeyChecking=no index.html ubuntu@43.160.229.161:/home/ubuntu/ 2>/dev/null &&
    scp -i /root/.ssh/lobster_deploy -o StrictHostKeyChecking=no data/twitter_translated.json ubuntu@43.160.229.161:/home/ubuntu/ 2>/dev/null &&
    ssh -i /root/.ssh/lobster_deploy -o StrictHostKeyChecking=no ubuntu@43.160.229.161 'sudo cp /home/ubuntu/index.html /var/www/html/ && sudo cp /home/ubuntu/twitter_translated.json /var/www/html/data/ && sudo chown www-data:www-data /var/www/html/index.html /var/www/html/data/twitter_translated.json' 2>/dev/null
    """
    
    try:
        result = subprocess.run(deploy_cmd, shell=True, capture_output=True, text=True, timeout=60)
        if result.returncode == 0:
            print("âœ… éƒ¨ç½²æˆåŠŸ!")
        else:
            print(f"âš ï¸ éƒ¨ç½²è­¦å‘Š")
    except Exception as e:
        print(f"âŒ éƒ¨ç½²å¤±è´¥: {e}")

async def main():
    print(f"\n{'='*60}")
    print(f"ğŸ¦ Twitter è‡ªåŠ¨æ›´æ–° - {datetime.now().strftime('%H:%M')}")
    print(f"{'='*60}")
    
    tweets = await fetch_tweets()
    if tweets:
        save_and_deploy(tweets)
        total = sum(len(v) for v in tweets.values())
        print(f"âœ… æ€»è®¡: {total} æ¡æ¨æ–‡")
    else:
        print("âš ï¸ æ— æ•°æ®")
    
    print(f"{'='*60}\n")

if __name__ == '__main__':
    asyncio.run(main())
