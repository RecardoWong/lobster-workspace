#!/usr/bin/env python3
"""
Twitter è‡ªåŠ¨ç›‘æ§ + ç¿»è¯‘ + éƒ¨ç½²
æ¯å°æ—¶è‡ªåŠ¨è¿è¡Œï¼Œæ— éœ€äººå·¥å¹²é¢„
"""

import os
import json
import asyncio
import subprocess
import urllib.request
import urllib.parse
import re
from datetime import datetime, timezone, timedelta

def translate_text(text):
    """ç¿»è¯‘æ–‡æœ¬ - ä½¿ç”¨ MyMemory API (å…è´¹)"""
    if not text:
        return ""
    
    # å¦‚æœå·²ç»æ˜¯ä¸­æ–‡ï¼Œç›´æ¥è¿”å›
    if any('\u4e00' <= char <= '\u9fff' for char in text[:50]):
        return text
    
    # é¢„å®šä¹‰ç¿»è¯‘ï¼ˆå¸¸ç”¨çŸ­è¯­ï¼‰
    translations = {
        "Cybercab, which has no pedals or steering wheel, starts production in April": "Cybercabæ— äººé©¾é©¶å‡ºç§Ÿè½¦å°†äº4æœˆæŠ•äº§",
        "The Meaning of Life": "ç”Ÿå‘½çš„æ„ä¹‰",
        "After-market buzz": "ç›˜åçƒ­ç‚¹",
        "After-Market Earnings Recap": "ç›˜åè´¢æŠ¥å›é¡¾",
    }
    
    # æ£€æŸ¥é¢„å®šä¹‰
    for key, value in translations.items():
        if key.lower() in text.lower() or text.lower() in key.lower():
            return value
    
    # ä½¿ç”¨ MyMemory API ç¿»è¯‘
    try:
        encoded_text = urllib.parse.quote(text[:300])
        url = f"https://api.mymemory.translated.net/get?q={encoded_text}&langpair=en|zh-CN"
        
        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=10) as response:
            data = json.loads(response.read().decode('utf-8'))
            if data.get('responseStatus') == 200:
                translated = data.get('responseData', {}).get('translatedText', '')
                if translated and translated != text:
                    return translated
    except Exception as e:
        print(f"  ç¿»è¯‘APIå¤±è´¥: {e}")
    
    # å›é€€ï¼šè¿”å›åŸæ–‡æ‘˜è¦
    return text[:100] + "..." if len(text) > 100 else text

# é…ç½®
MONITOR_ACCOUNTS = {
    'elonmusk': 'Elon Musk',
    'jdhasoptions': 'jdhasoptions', 
    'xiaomucrypto': 'xiaomucrypto',
    'aistocksavvy': 'AI Stock Savvy'
}

SAVE_DIR = '/tmp/twitter_monitor'
DASHBOARD_DATA = '/root/.openclaw/workspace/lobster-workspace/dashboard/data/twitter_translated.json'

def get_time_ago(time_str):
    """è®¡ç®—ç›¸å¯¹æ—¶é—´"""
    try:
        tweet_time = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
        now = datetime.now(timezone.utc)
        diff = now - tweet_time
        if diff.days > 0:
            return f"{diff.days}å¤©å‰"
        hours = diff.seconds // 3600
        if hours > 0:
            return f"{hours}å°æ—¶å‰"
        return "åˆšåˆš"
    except:
        return "æœªçŸ¥"

async def fetch_tweets():
    """è¯»å–æŠ“å–çš„æ•°æ®æ–‡ä»¶"""
    print("ğŸ¦ è¯»å– Twitter æ•°æ®...")
    
    all_tweets = {}
    for username, name in MONITOR_ACCOUNTS.items():
        import glob
        files = glob.glob(f"{SAVE_DIR}/{username}_*.json")
        
        if not files:
            print(f"   âš ï¸ {name}: æ— æ–‡ä»¶")
            continue
        
        # æ‰¾æœ€æ–°ä¸”æœ‰æ•°æ®çš„æ–‡ä»¶
        files.sort(key=os.path.getctime, reverse=True)
        latest = None
        for f in files:
            try:
                with open(f, 'r', encoding='utf-8') as fp:
                    data = json.load(fp)
                if len(data.get('tweets', [])) > 0:
                    latest = f
                    break
            except:
                continue
        
        if not latest:
            print(f"   âš ï¸ {name}: æ— æœ‰æ•ˆæ•°æ®")
            continue
        
        try:
            with open(latest, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            tweets_data = data.get('tweets', [])
            tweets = []
            for item in tweets_data[:3]:
                text = item.get('text', '')
                tweet_id = str(item.get('id', ''))
                tweets.append({
                    'author': username,
                    'name': name,
                    'text': text[:150] + "..." if len(text) > 150 else text,
                    'translate': translate_text(text),
                    'time': item.get('time', ''),
                    'time_ago': get_time_ago(item.get('time', '')),
                    'url': f"https://x.com/{username}/status/{tweet_id}" if tweet_id else f"https://x.com/{username}"
                })
            
            all_tweets[username] = tweets
            print(f"  âœ… {name}: {len(tweets)} æ¡ ({os.path.basename(latest)})")
            
        except Exception as e:
            print(f"  âŒ {name}: {e}")
    
    return all_tweets

def save_and_deploy(tweets_data):
    """ä¿å­˜ JSON å¹¶æ›´æ–° HTML é™æ€åµŒå…¥"""
    now = datetime.now()
    output = {
        'update_time': now.isoformat(),
        'tweets': tweets_data
    }
    
    # ä¿å­˜ JSON
    os.makedirs(os.path.dirname(DASHBOARD_DATA), exist_ok=True)
    with open(DASHBOARD_DATA, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    print(f"âœ… JSON å·²ä¿å­˜")
    
    # ç”Ÿæˆ HTML åµŒå…¥å†…å®¹
    html_content = generate_twitter_html(tweets_data, now)
    
    # æ›´æ–° Dashboard HTML
    update_dashboard_html(html_content, now)
    
    # éƒ¨ç½²åˆ°æœåŠ¡å™¨
    print("ğŸš€ éƒ¨ç½²åˆ°æœåŠ¡å™¨...")
    deploy_dashboard()

def generate_twitter_html(tweets_data, now):
    """ç”Ÿæˆ Twitter HTML åµŒå…¥å†…å®¹"""
    html_parts = []
    
    for username, tweets in tweets_data.items():
        for tweet in tweets:
            # è½¬ä¹‰ HTML ç‰¹æ®Šå­—ç¬¦
            text = tweet['text'].replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;').replace('"', '&quot;')
            translate = tweet['translate'].replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;').replace('"', '&quot;')
            
            html_parts.append(f'''\n<a href="{tweet['url']}" target="_blank" style="text-decoration: none; color: inherit; display: block; margin-bottom: 12px; padding: 12px; border-radius: 8px; transition: background 0.2s;" class="tweet-link">\n<div class="tweet-item" style="cursor: pointer;">\n<div class="tweet-author"><span class="tweet-author-name">{tweet['name']}</span><span class="tweet-author-handle">@{tweet['author']}</span><span class="tweet-time">{tweet['time_ago']}</span></div>\n<div class="tweet-text">{text}</div>\n<div class="tweet-translate"><span style="color: #3b82f6; font-size: 11px;">[ä¸­æ–‡ç¿»è¯‘]</span> {translate}</div>\n<div style="margin-top: 8px; font-size: 11px; color: #9ca3af; text-align: right;">ğŸ”— ç‚¹å‡»æŸ¥çœ‹åŸæ¨æ–‡ â†’</div>\n</div>\n</a>''')
    
    return '\n'.join(html_parts)

def update_dashboard_html(twitter_html, now):
    """æ›´æ–° Dashboard HTML æ–‡ä»¶"""
    html_path = '/root/.openclaw/workspace/lobster-workspace/dashboard/index.html'
    
    with open(html_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ›´æ–°æ—¶é—´æ ‡ç­¾
    time_str = now.strftime('%Y-%m-%d %H:%M')
    content = re.sub(
        r'(<span[^>]*id="twitterUpdateTime"[^>]*>)æ›´æ–°äº: [^<]+</span>',
        f'\\g<1>æ›´æ–°äº: {time_str}</span>',
        content
    )
    
    # æ›´æ–° Twitter å†…å®¹åŒºåŸŸ (åœ¨ id="twitterContainer" çš„ div ä¸­)
    pattern = r'(<div class="card-body" id="twitterContainer">)[\s\S]*?(</div>\s*<div class="card"[^>]*>|</div>\s*</main>)'
    replacement = f'\\g<1>{twitter_html}\\g<2>'
    content = re.sub(pattern, replacement, content, count=1)
    
    with open(html_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ… HTML å·²æ›´æ–° ({time_str})")

def deploy_dashboard():
    """éƒ¨ç½² Dashboard"""
    deploy_cmd = """
    cd /root/.openclaw/workspace/lobster-workspace/dashboard && 
    scp -i /root/.ssh/lobster_deploy -o StrictHostKeyChecking=no index.html ubuntu@43.160.229.161:/home/ubuntu/ 2>/dev/null &&
    scp -i /root/.ssh/lobster_deploy -o StrictHostKeyChecking=no data/twitter_translated.json ubuntu@43.160.229.161:/home/ubuntu/ 2>/dev/null &&
    ssh -i /root/.ssh/lobster_deploy -o StrictHostKeyChecking=no ubuntu@43.160.229.161 'sudo cp /home/ubuntu/index.html /var/www/html/ && sudo cp /home/ubuntu/twitter_translated.json /var/www/html/data/ && sudo chown www-data:www-data /var/www/html/index.html /var/www/html/data/twitter_translated.json' 2>/dev/null
    """
    
    try:
        result = subprocess.run(deploy_cmd, shell=True, capture_output=True, text=True, timeout=60)
        if result.returncode == 0:
            print("âœ… éƒ¨ç½²æˆåŠŸ!")
        else:
            print(f"âš ï¸ éƒ¨ç½²è­¦å‘Š")
    except Exception as e:
        print(f"âŒ éƒ¨ç½²å¤±è´¥: {e}")

async def main():
    print(f"\n{'='*60}")
    print(f"ğŸ¦ Twitter è‡ªåŠ¨æ›´æ–° - {datetime.now().strftime('%H:%M')}")
    print(f"{'='*60}")
    
    tweets = await fetch_tweets()
    if tweets:
        save_and_deploy(tweets)
        total = sum(len(v) for v in tweets.values())
        print(f"âœ… æ€»è®¡: {total} æ¡æ¨æ–‡")
    else:
        print("âš ï¸ æ— æ•°æ®")
    
    print(f"{'='*60}\n")

if __name__ == '__main__':
    asyncio.run(main())
