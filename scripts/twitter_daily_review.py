#!/usr/bin/env python3
"""
Twitter æ¯æ—¥å¤ç›˜
è¯»å–å‰ä¸€å¤©è®°å½•çš„æ¨æ–‡ï¼Œç”Ÿæˆå¤ç›˜æŠ¥å‘Š
"""

import os
import re
from datetime import datetime, timedelta
from pathlib import Path

LOG_DIR = '/root/.openclaw/workspace/memory/twitter_logs'

def parse_daily_log(date_str):
    """è§£ææŸä¸€å¤©çš„Markdownæ—¥å¿—"""
    log_file = f"{LOG_DIR}/{date_str}.md"
    
    if not os.path.exists(log_file):
        return None
    
    with open(log_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # è§£ææ¨æ–‡
    tweets = []
    tweet_blocks = re.split(r'### ', content)[1:]  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºå—
    
    for block in tweet_blocks:
        lines = block.strip().split('\n')
        if not lines:
            continue
        
        # ç¬¬ä¸€è¡Œæ˜¯ä½œè€…å
        author_line = lines[0].strip()
        match = re.match(r'(.+?) \(@(.+?)\)', author_line)
        if match:
            name = match.group(1)
            author = match.group(2)
        else:
            name = author_line
            author = 'unknown'
        
        # æå–å…¶ä»–ä¿¡æ¯
        tweet = {'name': name, 'author': author}
        for line in lines[1:]:
            if line.startswith('- æ—¶é—´:'):
                tweet['time_info'] = line.replace('- æ—¶é—´:', '').strip()
            elif line.startswith('- åŸæ–‡:'):
                tweet['text'] = line.replace('- åŸæ–‡:', '').strip()
            elif line.startswith('- ç¿»è¯‘:'):
                tweet['translate'] = line.replace('- ç¿»è¯‘:', '').strip()
            elif line.startswith('- é“¾æ¥:'):
                tweet['url'] = line.replace('- é“¾æ¥:', '').strip()
        
        tweets.append(tweet)
    
    return tweets

def analyze_tweets(tweets):
    """åˆ†ææ¨æ–‡å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯"""
    if not tweets:
        return None
    
    # æŒ‰ä½œè€…åˆ†ç»„
    by_author = {}
    for t in tweets:
        author = t.get('author', 'unknown')
        if author not in by_author:
            by_author[author] = []
        by_author[author].append(t)
    
    # æå–å…³é”®è¯/ä¸»é¢˜
    all_text = ' '.join([t.get('text', '') + ' ' + t.get('translate', '') for t in tweets])
    
    # ç®€å•çš„ä¸»é¢˜è¯†åˆ«
    themes = []
    keywords = {
        'AI/ç§‘æŠ€': ['AI', 'Grok', 'OpenAI', 'äººå·¥æ™ºèƒ½', 'ç§‘æŠ€'],
        'è‚¡ç¥¨/æŠ•èµ„': ['stock', 'earnings', 'è´¢æŠ¥', 'è‚¡ç¥¨', 'çœ‹æ¶¨', 'æœŸæƒ'],
        'åŠ å¯†è´§å¸': ['crypto', 'bitcoin', 'BTC', 'åŠ å¯†è´§å¸', 'äº¤æ˜“æ‰€'],
        'åœ°ç¼˜æ”¿æ²»': ['war', 'war', 'æ‰“ä»—', 'å›½é˜²', 'å†›äº‹'],
        'å®è§‚/ç»æµ': ['fed', 'rate', 'åˆ©ç‡', 'ç»æµ', 'é€šèƒ€']
    }
    
    for theme, words in keywords.items():
        if any(word.lower() in all_text.lower() for word in words):
            themes.append(theme)
    
    return {
        'by_author': by_author,
        'themes': themes,
        'total': len(tweets)
    }

def generate_report(date_str, analysis):
    """ç”Ÿæˆå¤ç›˜æŠ¥å‘Š"""
    if not analysis:
        return f"ğŸ“… {date_str} æ²¡æœ‰æ¨æ–‡è®°å½•"
    
    by_author = analysis['by_author']
    themes = analysis['themes']
    total = analysis['total']
    
    lines = [
        f"ğŸ“Š Twitter æ¯æ—¥å¤ç›˜ ({date_str})",
        f"ğŸ“ˆ æ€»è®¡: {total} æ¡æ¨æ–‡",
        f"ğŸ·ï¸ ä¸»é¢˜: {', '.join(themes) if themes else 'æ— æ˜ç¡®ä¸»é¢˜'}",
        "=" * 40,
        ""
    ]
    
    # å„ä½œè€…æ€»ç»“
    for author, tweets in by_author.items():
        name = tweets[0].get('name', author)
        lines.extend([
            f"ğŸ‘¤ {name} (@{author}) - {len(tweets)}æ¡",
            ""
        ])
        
        # æå–å…³é”®æ¨æ–‡ï¼ˆå‰3æ¡ï¼‰
        for i, t in enumerate(tweets[:3], 1):
            text = t.get('text', '')[:80]
            translate = t.get('translate', '')[:60]
            lines.append(f"  {i}. {text}...")
            if translate and translate != text:
                lines.append(f"     ğŸ“ {translate}...")
        
        lines.append("")
    
    # å¸‚åœºä¿¡å·æ€»ç»“
    lines.extend([
        "ğŸ” å¸‚åœºä¿¡å·:",
        ""
    ])
    
    # æ ¹æ®ä¸»é¢˜ç”Ÿæˆä¿¡å·
    if 'åœ°ç¼˜æ”¿æ²»' in themes:
        lines.append("  âš ï¸ åœ°ç¼˜æ”¿æ²»é£é™©æåŠ - å…³æ³¨å›½é˜²è‚¡ã€èƒ½æºè‚¡")
    if 'è‚¡ç¥¨/æŠ•èµ„' in themes:
        lines.append("  ğŸ“ˆ æŠ•èµ„è®¨è®ºæ´»è·ƒ - å…³æ³¨æåŠä¸ªè‚¡")
    if 'AI/ç§‘æŠ€' in themes:
        lines.append("  ğŸ¤– AIè¯é¢˜çƒ­åº¦é«˜ - å…³æ³¨ç§‘æŠ€è‚¡")
    if 'åŠ å¯†è´§å¸' in themes:
        lines.append("  â‚¿ åŠ å¯†å¸‚åœºè®¨è®º - å…³æ³¨ç›¸å…³èµ„äº§")
    
    if not themes:
        lines.append("  â„¹ï¸ ä»Šæ—¥è®¨è®ºè¾ƒåˆ†æ•£ï¼Œæ— é›†ä¸­ä¸»é¢˜")
    
    # æ“ä½œå»ºè®®
    lines.extend([
        "",
        "ğŸ’¡ æ“ä½œå»ºè®®:",
        ""
    ])
    
    if total > 20:
        lines.append("  â€¢ æ¨æ–‡æ—…å¯†åº¦é«˜ï¼Œå¯èƒ½æœ‰é‡è¦äº‹ä»¶ï¼Œå»ºè®®å…³æ³¨å¸‚åœºå¼€ç›˜")
    elif total > 10:
        lines.append("  â€¢ è®¨è®ºçƒ­åº¦ä¸­ç­‰ï¼Œä¿æŒå¸¸è§„å…³æ³¨")
    else:
        lines.append("  â€¢ è®¨è®ºè¾ƒå°‘ï¼Œå¸‚åœºå¯èƒ½ç›¸å¯¹å¹³é™")
    
    if 'åœ°ç¼˜æ”¿æ²»' in themes:
        lines.append("  â€¢ å»ºè®®å…³æ³¨VIXæ³¢åŠ¨ç‡æŒ‡æ•°å’Œé»„é‡‘èµ°åŠ¿")
    if 'AI/ç§‘æŠ€' in themes:
        lines.append("  â€¢ å»ºè®®å…³æ³¨NVDAã€AIç›¸å…³æ¿å—")
    
    lines.extend([
        "",
        "=" * 40,
        f"ğŸ“… å¤ç›˜æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}"
    ])
    
    return "\n".join(lines)

def main():
    # è·å–æ˜¨å¤©æ—¥æœŸ
    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    
    print(f"[{datetime.now().strftime('%H:%M')}] ç”Ÿæˆ {yesterday} çš„Twitterå¤ç›˜...")
    
    # è§£ææ—¥å¿—
    tweets = parse_daily_log(yesterday)
    
    if tweets:
        # åˆ†æ
        analysis = analyze_tweets(tweets)
        # ç”ŸæˆæŠ¥å‘Š
        report = generate_report(yesterday, analysis)
        print(report)
    else:
        print(f"âš ï¸ {yesterday} æ²¡æœ‰æ‰¾åˆ°æ¨æ–‡è®°å½•")

if __name__ == '__main__':
    main()
