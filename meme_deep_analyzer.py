#!/usr/bin/env python3
"""
Memeå¸æ·±åº¦åˆ†æç³»ç»Ÿ v4.0
åŠŸèƒ½ï¼š
1. è¯†åˆ«æ–°å‡ºç°çš„åˆçº¦ï¼ˆé¦–æ¬¡å‡ºç°ï¼‰
2. åˆ†æåœŸç‹—å™äº‹ï¼ˆæ•…äº‹/æ¦‚å¿µï¼‰
3. åˆ†æç«çš„åŸå› ï¼ˆäº¤æ˜“é‡/ä»·æ ¼/ç¤¾åª’ï¼‰
"""

import urllib.request
import json
import os
from datetime import datetime
from typing import Dict, List, Optional, Set

class ContractDatabase:
    """åˆçº¦æ•°æ®åº“ - è®°å½•å†å²åˆçº¦"""
    
    def __init__(self, db_file: str = "/tmp/meme_contracts_db.json"):
        self.db_file = db_file
        self.known_contracts: Set[str] = set()
        self.contract_history: Dict = {}
        self.load()
    
    def load(self):
        """åŠ è½½å†å²æ•°æ®"""
        if os.path.exists(self.db_file):
            try:
                with open(self.db_file, 'r') as f:
                    data = json.load(f)
                    self.known_contracts = set(data.get('contracts', []))
                    self.contract_history = data.get('history', {})
            except:
                pass
    
    def save(self):
        """ä¿å­˜æ•°æ®"""
        data = {
            'contracts': list(self.known_contracts),
            'history': self.contract_history,
            'last_update': datetime.now().isoformat()
        }
        with open(self.db_file, 'w') as f:
            json.dump(data, f, indent=2)
    
    def is_new(self, address: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ–°åˆçº¦"""
        return address.lower() not in self.known_contracts
    
    def add(self, address: str, info: Dict):
        """æ·»åŠ åˆçº¦"""
        self.known_contracts.add(address.lower())
        self.contract_history[address.lower()] = {
            'first_seen': datetime.now().isoformat(),
            'info': info
        }
        self.save()


class NarrativeAnalyzer:
    """å™äº‹åˆ†æå™¨ - åˆ†æåœŸç‹—çš„æ•…äº‹å’Œæ¦‚å¿µ"""
    
    # å™äº‹æ¨¡å¼åº“
    NARRATIVES = {
        'meme_culture': {
            'keywords': ['pepe', 'doge', 'shib', 'wojak', 'chad', 'based'],
            'description': 'ğŸ¸ Memeæ–‡åŒ–å¸ - ä¾é ç¤¾åŒºä¼ æ’­å’Œè¡¨æƒ…åŒ…é©±åŠ¨'
        },
        'ai_concept': {
            'keywords': ['ai', 'gpt', 'bot', 'neural', 'intelligence', 'robot'],
            'description': 'ğŸ¤– AIæ¦‚å¿µå¸ - è¹­AIçƒ­åº¦ï¼Œå£°ç§°æœ‰æŠ€æœ¯æˆ–åº”ç”¨åœºæ™¯'
        },
        'celebrity': {
            'keywords': ['elon', 'musk', 'trump', 'elmo', 'donald', 'musk'],
            'description': 'ğŸš€ åäººæ¦‚å¿µå¸ - è¹­åäºº/æ”¿å®¢çƒ­åº¦'
        },
        'animal': {
            'keywords': ['cat', 'dog', 'frog', 'bird', 'wolf', 'bear', 'bull'],
            'description': 'ğŸ• åŠ¨ç‰©å¸ - å¯çˆ±åŠ¨ç‰©å½¢è±¡ï¼Œå®¹æ˜“ä¼ æ’­'
        },
        'moon_money': {
            'keywords': ['moon', 'mars', 'rocket', 'lambo', 'rich', 'money', 'wealth'],
            'description': 'ğŸŒ™ æš´å¯Œæ¦‚å¿µå¸ - å¼ºè°ƒæš´å¯Œã€ä¸Šæœˆçƒç­‰è´¢å¯Œè‡ªç”±å™äº‹'
        },
        'community': {
            'keywords': ['community', 'dao', 'together', 'united', 'hold', 'army'],
            'description': 'ğŸ’ª ç¤¾åŒºé©±åŠ¨å¸ - å¼ºè°ƒç¤¾åŒºåŠ›é‡ã€å›¢ç»“æŒå¸'
        },
        'base_ecosystem': {
            'keywords': ['base', 'build', 'onbase', 'basechain'],
            'description': 'ğŸ—ï¸ Baseç”Ÿæ€å¸ - å¼ºè°ƒåœ¨Baseé“¾ä¸Šæ„å»ºç”Ÿæ€'
        },
        'gaming': {
            'keywords': ['game', 'gaming', 'play', 'nft', 'metaverse', 'pvp'],
            'description': 'ğŸ® æ¸¸æˆæ¦‚å¿µå¸ - GameFiæˆ–å…ƒå®‡å®™ç›¸å…³'
        }
    }
    
    def analyze(self, name: str, symbol: str) -> List[Dict]:
        """åˆ†æä»£å¸å™äº‹"""
        text = (name + " " + symbol).lower()
        narratives = []
        
        for key, data in self.NARRATIVES.items():
            match_score = sum(1 for keyword in data['keywords'] if keyword in text)
            if match_score > 0:
                narratives.append({
                    'type': key,
                    'description': data['description'],
                    'match_score': match_score,
                    'matched_keywords': [k for k in data['keywords'] if k in text]
                })
        
        # æŒ‰åŒ¹é…åº¦æ’åº
        narratives.sort(key=lambda x: x['match_score'], reverse=True)
        return narratives
    
    def generate_story(self, name: str, symbol: str, narratives: List[Dict]) -> str:
        """ç”Ÿæˆä»£å¸æ•…äº‹"""
        if not narratives:
            return f"ğŸ“– {symbol} - æš‚æ— æ˜ç¡®å™äº‹ï¼Œå¯èƒ½æ˜¯å®éªŒæ€§é¡¹ç›®æˆ–ç­‰å¾…ç¤¾åŒºå‘ç°ä»·å€¼"
        
        top_narrative = narratives[0]
        story = f"ğŸ“– {symbol} ({name})\n"
        story += f"   æ ¸å¿ƒå™äº‹: {top_narrative['description']}\n"
        
        if len(narratives) > 1:
            story += f"   æ¬¡è¦å™äº‹: {narratives[1]['description']}\n"
        
        # æ ¹æ®å™äº‹ç”Ÿæˆé¢„æœŸ
        if top_narrative['type'] == 'meme_culture':
            story += "   ğŸ“ˆ çˆ†å‘æ½œåŠ›: ä¾èµ–KOLå–Šå•å’Œç¤¾åŒºä¼ æ’­ï¼Œå¯èƒ½å¿«é€Ÿæš´æ¶¨ä½†æŒç»­æ€§å·®"
        elif top_narrative['type'] == 'ai_concept':
            story += "   ğŸ“ˆ çˆ†å‘æ½œåŠ›: AIçƒ­åº¦æŒç»­ï¼Œå¦‚æœ‰å®é™…åº”ç”¨åœºæ™¯å¯èƒ½é•¿æœŸä¸Šæ¶¨"
        elif top_narrative['type'] == 'celebrity':
            story += "   âš ï¸ é£é™©æç¤º: åäººæ¦‚å¿µå¸å®¹æ˜“å› åäººä¸€å¥è¯æš´æ¶¨æš´è·Œ"
        elif top_narrative['type'] == 'moon_money':
            story += "   âš ï¸ é£é™©æç¤º: æš´å¯Œå™äº‹é€šå¸¸æ˜¯å‰²éŸ­èœä¿¡å·ï¼Œéœ€è­¦æƒ•"
        
        return story


class HypeAnalyzer:
    """ç«çˆ†åŸå› åˆ†æå™¨"""
    
    def analyze(self, token: Dict) -> Dict:
        """åˆ†æä¸ºä»€ä¹ˆç«"""
        reasons = []
        indicators = {
            'volume_explosion': False,
            'price_pump': False,
            'new_listing': False,
            'whale_activity': False,
            'social_hype': False
        }
        
        change = token.get('change_24h', 0)
        volume = token.get('volume_24h', 0)
        liquidity = token.get('liquidity', 0)
        tx_count = token.get('tx_count', 0)
        
        # 1. äº¤æ˜“é‡çˆ†å‘
        volume_ratio = volume / liquidity if liquidity > 0 else 0
        if volume_ratio > 5:
            reasons.append("ğŸ”¥ğŸ”¥ğŸ”¥ äº¤æ˜“é‡æåº¦çˆ†å‘ - èµ„é‡‘ç–¯ç‹‚æ¶Œå…¥ï¼Œå¯èƒ½é‡å¤§åˆ©å¥½")
            indicators['volume_explosion'] = True
        elif volume_ratio > 2:
            reasons.append("ğŸ”¥ğŸ”¥ äº¤æ˜“é‡æ¿€å¢ - å…³æ³¨åº¦å¿«é€Ÿæå‡")
            indicators['volume_explosion'] = True
        elif volume_ratio > 1:
            reasons.append("ğŸ”¥ äº¤æ˜“æ´»è·ƒ - æ­£å¸¸çƒ­åº¦")
        
        # 2. ä»·æ ¼æš´æ¶¨
        if change > 500:
            reasons.append("ğŸš€ğŸš€ğŸš€ è¶…çº§æš´æ¶¨(500%+) - å¯èƒ½æ˜¯ä¸Šæ‰€/é‡å¤§åˆä½œ/ç—…æ¯’å¼ä¼ æ’­")
            indicators['price_pump'] = True
        elif change > 200:
            reasons.append("ğŸš€ğŸš€ æš´æ¶¨(200%+) - KOLå–Šå•æˆ–ç¤¾åŒºFOMO")
            indicators['price_pump'] = True
        elif change > 100:
            reasons.append("ğŸš€ å¤§å¹…ä¸Šæ¶¨(100%+) - ä¹°ç›˜å¼ºåŠ²")
            indicators['price_pump'] = True
        
        # 3. æ–°å¸ä¸Šçº¿ç‰¹å¾
        if liquidity < 50000 and volume > liquidity * 3:
            reasons.append("ğŸ†• ç–‘ä¼¼æ–°å¸ä¸Šçº¿ - åˆšå‘å°„å°±è¢«å¤§é‡ä¹°å…¥ï¼Œæ—©æœŸæœºä¼šä½†é£é™©æé«˜")
            indicators['new_listing'] = True
        
        # 4. é²¸é±¼æ´»åŠ¨ç‰¹å¾
        if tx_count < 50 and volume > 100000:
            reasons.append("ğŸ‹ é²¸é±¼æ§ç›˜è¿¹è±¡ - äº¤æ˜“ç¬”æ•°å°‘ä½†é‡‘é¢å¤§ï¼Œå¤§æˆ·åœ¨æ“ç›˜")
            indicators['whale_activity'] = True
        
        # 5. æ•£æˆ·FOMO
        if tx_count > 500 and change > 50:
            reasons.append("ğŸ‘¥ æ•£æˆ·FOMOä¸¥é‡ - å¤§é‡å°å•ä¹°å…¥ï¼Œç¤¾åŒºæƒ…ç»ªç‹‚çƒ­")
            indicators['social_hype'] = True
        
        # ç»¼åˆåˆ¤æ–­
        if not reasons:
            if change > 0:
                reasons.append("ğŸ“Š æ¸©å’Œä¸Šæ¶¨ - æ­£å¸¸å¸‚åœºæ³¢åŠ¨")
            else:
                reasons.append("ğŸ“‰ å›è°ƒä¸­ - è·åˆ©ç›˜å‡ºè´§æˆ–å¸‚åœºæƒ…ç»ªè½¬å†·")
        
        return {
            'reasons': reasons,
            'indicators': indicators,
            'hype_score': self._calculate_hype_score(indicators, change, volume_ratio)
        }
    
    def _calculate_hype_score(self, indicators: Dict, change: float, volume_ratio: float) -> int:
        """è®¡ç®—çƒ­åº¦åˆ†æ•°"""
        score = 0
        if indicators['volume_explosion']: score += 30
        if indicators['price_pump']: score += 30
        if indicators['new_listing']: score += 20
        if indicators['whale_activity']: score += 10
        if indicators['social_hype']: score += 10
        
        # ä»·æ ¼åŠ æˆ
        if change > 200: score += 20
        elif change > 100: score += 15
        elif change > 50: score += 10
        
        # äº¤æ˜“é‡åŠ æˆ
        if volume_ratio > 5: score += 10
        elif volume_ratio > 2: score += 5
        
        return min(100, score)


class MemeCoinDeepAnalyzer:
    """Memeå¸æ·±åº¦åˆ†æå™¨"""
    
    def __init__(self):
        self.db = ContractDatabase()
        self.narrative = NarrativeAnalyzer()
        self.hype = HypeAnalyzer()
    
    def get_base_tokens(self) -> List[Dict]:
        """è·å–Baseé“¾ä»£å¸"""
        try:
            url = "https://api.dexscreener.com/latest/dex/search?q=base%20chain"
            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, timeout=15) as resp:
                data = json.loads(resp.read().decode('utf-8'))
                pairs = data.get('pairs', [])
                
                tokens = []
                seen = set()
                
                for pair in pairs:
                    if pair.get('chainId', '').lower() != 'base':
                        continue
                    
                    symbol = pair.get('baseToken', {}).get('symbol', '???')
                    address = pair.get('baseToken', {}).get('address', '')
                    
                    if symbol in seen or symbol == '???':
                        continue
                    seen.add(symbol)
                    
                    liquidity = float(pair.get('liquidity', {}).get('usd', 0) or 0)
                    if liquidity > 5000:  # è‡³å°‘$5KæµåŠ¨æ€§
                        tokens.append({
                            'name': pair.get('baseToken', {}).get('name', 'Unknown'),
                            'symbol': symbol,
                            'address': address,
                            'price': float(pair.get('priceUsd', 0) or 0),
                            'liquidity': liquidity,
                            'volume_24h': float(pair.get('volume', {}).get('h24', 0) or 0),
                            'change_24h': float(pair.get('priceChange', {}).get('h24', 0) or 0),
                            'tx_count': (pair.get('txns', {}).get('h24', {}).get('buys', 0) or 0) + 
                                       (pair.get('txns', {}).get('h24', {}).get('sells', 0) or 0),
                            'pair_url': pair.get('url', ''),
                            'is_new': self.db.is_new(address)
                        })
                
                # æŒ‰äº¤æ˜“é‡æ’åº
                tokens.sort(key=lambda x: x['volume_24h'], reverse=True)
                
                # æ–°åˆçº¦æ·»åŠ åˆ°æ•°æ®åº“
                for t in tokens:
                    if t['is_new']:
                        self.db.add(t['address'], {
                            'name': t['name'],
                            'symbol': t['symbol'],
                            'first_seen_price': t['price']
                        })
                
                return tokens[:10]
                
        except Exception as e:
            print(f"âŒ è·å–æ•°æ®å¤±è´¥: {e}")
            return []
    
    def generate_report(self) -> str:
        """ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š"""
        print("ğŸ” æ­£åœ¨æ·±åº¦åˆ†æBaseé“¾Memeå¸...")
        tokens = self.get_base_tokens()
        
        if not tokens:
            return "âš ï¸ æœªèƒ½è·å–æ•°æ®"
        
        lines = [
            "="*70,
            "ğŸš€ Baseé“¾Memeå¸æ·±åº¦åˆ†ææŠ¥å‘Š",
            f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "="*70,
            ""
        ]
        
        # æ–°åˆçº¦é¢„è­¦
        new_tokens = [t for t in tokens if t['is_new']]
        if new_tokens:
            lines.extend([
                "ğŸ†• æ–°åˆçº¦é¢„è­¦ï¼ˆé¦–æ¬¡å‡ºç°ï¼‰",
                "-"*70,
            ])
            for t in new_tokens[:3]:
                lines.append(f"âš ï¸ {t['symbol']} - ä»Šæ—¥é¦–æ¬¡å‡ºç°ï¼")
                lines.append(f"   åˆçº¦: {t['address'][:20]}...")
                lines.append(f"   ä»·æ ¼: ${t['price']:.8f} | æµåŠ¨æ€§: ${t['liquidity']:,.0f}")
            lines.append("")
        
        # è¯¦ç»†åˆ†ææ¯åªå¸
        lines.extend([
            "="*70,
            "ğŸ“‹ æ·±åº¦åˆ†æï¼šå™äº‹ + ç«çˆ†åŸå› ",
            "="*70,
            ""
        ])
        
        for i, token in enumerate(tokens[:5], 1):
            # åŸºæœ¬ä¿¡æ¯
            new_flag = " ğŸ†•æ–°" if token['is_new'] else ""
            lines.extend([
                f"\n{'â”€'*70}",
                f"#{i} {token['symbol']}{new_flag} ({token['name']})",
                f"{'â”€'*70}",
                f"ğŸ’° ä»·æ ¼: ${token['price']:.8f} | 24h: {token['change_24h']:+.2f}%",
                f"ğŸ’§ æµåŠ¨æ€§: ${token['liquidity']:,.0f} | äº¤æ˜“é‡: ${token['volume_24h']:,.0f}",
                ""
            ])
            
            # å™äº‹åˆ†æ
            narratives = self.narrative.analyze(token['name'], token['symbol'])
            story = self.narrative.generate_story(token['name'], token['symbol'], narratives)
            lines.append(story)
            lines.append("")
            
            # ç«çˆ†åŸå› åˆ†æ
            hype = self.hype.analyze(token)
            lines.append("ğŸ”¥ ç«çˆ†åŸå› åˆ†æ:")
            for reason in hype['reasons']:
                lines.append(f"   {reason}")
            lines.append(f"\n   ğŸ“Š çƒ­åº¦è¯„åˆ†: {hype['hype_score']}/100")
            
            # äº¤æ˜“å»ºè®®
            if hype['hype_score'] >= 80:
                lines.append("\n   ğŸ¯ å»ºè®®: æåº¦ç«çˆ†ï¼Œå¯å°ä»“ä½å‚ä¸ä½†è®¾å¥½æ­¢æŸ")
            elif hype['hype_score'] >= 60:
                lines.append("\n   ğŸ¯ å»ºè®®: çƒ­åº¦è¾ƒé«˜ï¼Œå¯è§‚å¯Ÿç­‰å¾…å›è°ƒ")
            elif hype['hype_score'] >= 40:
                lines.append("\n   ğŸ¯ å»ºè®®: æ¸©å’Œçƒ­åº¦ï¼Œé€‚åˆåŸ‹ä¼")
            else:
                lines.append("\n   ğŸ¯ å»ºè®®: çƒ­åº¦è¾ƒä½ï¼Œè§‚æœ›ä¸ºä¸»")
            
            lines.append(f"\nğŸ”— {token['pair_url']}")
        
        lines.extend([
            "",
            "="*70,
            "âš ï¸ é£é™©æç¤º: Memeå¸é«˜é£é™©ï¼Œä»¥ä¸Šåˆ†æä»…ä¾›å‚è€ƒ",
            "="*70
        ])
        
        return "\n".join(lines)


def main():
    """ä¸»å‡½æ•°"""
    analyzer = MemeCoinDeepAnalyzer()
    report = analyzer.generate_report()
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    filename = f"/tmp/meme_deep_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.txt"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {filename}")


if __name__ == "__main__":
    main()
