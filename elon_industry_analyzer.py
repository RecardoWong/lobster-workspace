#!/usr/bin/env python3
"""
ğŸš€ Elon Musk æ¨æ–‡æ·±åº¦åˆ†æç³»ç»Ÿ
æ—©æ™šä¸¤æ¬¡æŠ¥å‘Šï¼ˆ08:00 & 21:00ï¼‰
åŒ…å«äº§ä¸šæ·±åº¦å‰–æ
"""

import json
import urllib.request
from datetime import datetime, timedelta
from typing import List, Dict, Tuple
import os

class ElonIndustryAnalyzer:
    """Elonäº§ä¸šåˆ†æå¸ˆ"""
    
    def __init__(self):
        self.industries = {
            'tesla': {
                'name': 'ğŸš— Tesla (ç‰¹æ–¯æ‹‰)',
                'keywords': ['tesla', 'tsla', 'model s', 'model 3', 'model x', 'model y', 
                           'cybertruck', 'autopilot', 'fsd', 'supercharger', '4680', 
                           'gigafactory', 'æŸæ—å·¥å‚', 'ä¸Šæµ·å·¥å‚', 'ç”µåŠ¨è½¦', 'è‡ªåŠ¨é©¾é©¶'],
                'impact': 'high',
                'stock': 'TSLA'
            },
            'spacex': {
                'name': 'ğŸš€ SpaceX',
                'keywords': ['spacex', 'starship', 'falcon', 'dragon', 'starlink', 
                           'mars', 'mars mission', 'raptor', 'raptor engine', 
                           'space', 'rocket', 'æ˜Ÿèˆ°', 'ç«æ˜Ÿ', 'æ˜Ÿé“¾'],
                'impact': 'medium',
                'stock': None
            },
            'xai': {
                'name': 'ğŸ¤– xAI',
                'keywords': ['xai', 'grok', 'ai', 'artificial intelligence', 
                           'llm', 'machine learning', 'agi', 'äººå·¥æ™ºèƒ½', 'å¤§æ¨¡å‹'],
                'impact': 'high',
                'stock': None
            },
            'twitter': {
                'name': 'ğŸ¦ X (Twitter)',
                'keywords': ['x', 'twitter', 'tweet', 'social media', 'platform', 
                           'free speech', 'algorithm', 'æ¨ç‰¹', 'ç¤¾äº¤åª’ä½“'],
                'impact': 'medium',
                'stock': None
            },
            'neuralink': {
                'name': 'ğŸ§  Neuralink',
                'keywords': ['neuralink', 'brain chip', 'neural', 'bci', 
                           'brain computer interface', 'è„‘æœºæ¥å£', 'å¤§è„‘èŠ¯ç‰‡'],
                'impact': 'high',
                'stock': None
            },
            'boring': {
                'name': 'ğŸš‡ The Boring Company',
                'keywords': ['boring company', 'hyperloop', 'tunnel', 'boring', 
                           'loop', 'éš§é“', 'é«˜é“'],
                'impact': 'low',
                'stock': None
            },
            'doge': {
                'name': 'ğŸ• Dogecoin',
                'keywords': ['doge', 'dogecoin', 'Ã', 'meme coin', 'crypto', 
                           'cryptocurrency', 'æ¯”ç‰¹å¸', 'åŠ å¯†è´§å¸', 'ç‹—ç‹—å¸'],
                'impact': 'high',
                'stock': None
            }
        }
    
    def analyze_tweet_industry(self, tweet_text: str) -> List[Dict]:
        """åˆ†ææ¨æ–‡æ¶‰åŠçš„äº§ä¸š"""
        text_lower = tweet_text.lower()
        matched_industries = []
        
        for industry_id, industry_info in self.industries.items():
            for keyword in industry_info['keywords']:
                if keyword in text_lower:
                    matched_industries.append(industry_info)
                    break
        
        return matched_industries
    
    def get_industry_analysis(self, industry_id: str) -> str:
        """è·å–äº§ä¸šæ·±åº¦åˆ†æ"""
        analyses = {
            'tesla': """
ğŸ“Š **Teslaäº§ä¸šåˆ†æ**
â€¢ **æ ¸å¿ƒåœ°ä½**: å…¨çƒç”µåŠ¨è½¦é¾™å¤´ï¼Œè‡ªåŠ¨é©¾é©¶æŠ€æœ¯é¢†å…ˆ
â€¢ **è¿‘æœŸç„¦ç‚¹**: Cybertrucké‡äº§ã€FSD v12æ¨å¹¿ã€4680ç”µæ± ã€ä¸Šæµ·/æŸæ—å·¥å‚
â€¢ **å¸‚åœºå½±å“**: æ¨æ–‡ç›´æ¥å½±å“TSLAè‚¡ä»·ï¼ˆÂ±5%æ³¢åŠ¨å¸¸è§ï¼‰
â€¢ **æŠ•èµ„è¦ç‚¹**: å…³æ³¨äº¤ä»˜é‡ã€æ¯›åˆ©ç‡ã€è‡ªåŠ¨é©¾é©¶è¿›å±•ã€äº§èƒ½çˆ¬å¡""",
            
            'spacex': """
ğŸ“Š **SpaceXäº§ä¸šåˆ†æ**
â€¢ **æ ¸å¿ƒåœ°ä½**: å…¨çƒæœ€å¤§ç§è¥èˆªå¤©å…¬å¸ï¼Œæ˜Ÿé“¾è¦†ç›–å…¨çƒ
â€¢ **è¿‘æœŸç„¦ç‚¹**: æ˜Ÿèˆ°ç¬¬äº”æ¬¡è¯•é£ã€æ˜Ÿé“¾IPOä¼ é—»ã€ç«æ˜Ÿè®¡åˆ’æ—¶é—´è¡¨
â€¢ **å¸‚åœºå½±å“**: è™½æœªä¸Šå¸‚ï¼Œä½†å½±å“èˆªå¤©æ¿å—åŠTeslaä¼°å€¼æº¢ä»·
â€¢ **æŠ•èµ„è¦ç‚¹**: å…³æ³¨æ˜Ÿèˆ°è¿›å±•ã€æ˜Ÿé“¾ç”¨æˆ·å¢é•¿ã€æ”¿åºœåˆåŒ""",
            
            'xai': """
ğŸ“Š **xAIäº§ä¸šåˆ†æ**
â€¢ **æ ¸å¿ƒåœ°ä½**: Elonæœ€æ–°AIå…¬å¸ï¼Œå¯¹æ ‡OpenAI
â€¢ **è¿‘æœŸç„¦ç‚¹**: GrokèŠå¤©æœºå™¨äººã€AIäººæ‰æ‹›è˜ã€ä¸Tesla AIååŒ
â€¢ **å¸‚åœºå½±å“**: AIå™äº‹çƒ­åº¦å½±å“ç§‘æŠ€è‚¡æ•´ä½“ä¼°å€¼
â€¢ **æŠ•èµ„è¦ç‚¹**: å…³æ³¨Grokç”¨æˆ·å¢é•¿ã€ç®—åŠ›å»ºè®¾ã€ä¸Tesla FSDæ•´åˆ""",
            
            'twitter': """
ğŸ“Š **X (Twitter)äº§ä¸šåˆ†æ**
â€¢ **æ ¸å¿ƒåœ°ä½**: å…¨çƒé‡è¦ç¤¾äº¤åª’ä½“å¹³å°ï¼ŒElonä¸ªäººå½±å“åŠ›çš„æ ¸å¿ƒè½½ä½“
â€¢ **è¿‘æœŸç„¦ç‚¹**: å¹¿å‘Šæ”¶å…¥æ¢å¤ã€åˆ›ä½œè€…åˆ†æˆã€AIå†…å®¹æ¨è
â€¢ **å¸‚åœºå½±å“**: å¹³å°æ”¿ç­–å˜åŒ–å½±å“åŠ å¯†è´§å¸ã€memeè‚¡è®¨è®ºçƒ­åº¦
â€¢ **æŠ•èµ„è¦ç‚¹**: å…³æ³¨å¹¿å‘Šå•†å›å½’ã€ä»˜è´¹ç”¨æˆ·å¢é•¿ã€ç®—æ³•é€æ˜åº¦""",
            
            'neuralink': """
ğŸ“Š **Neuralinkäº§ä¸šåˆ†æ**
â€¢ **æ ¸å¿ƒåœ°ä½**: è„‘æœºæ¥å£æŠ€æœ¯å…ˆé©±ï¼Œäººä½“è¯•éªŒå·²è·FDAæ‰¹å‡†
â€¢ **è¿‘æœŸç„¦ç‚¹**: é¦–ä½äººç±»æ¤å…¥è€…è¿›å±•ã€Telepathyäº§å“ã€åŒ»ç–—åº”ç”¨
â€¢ **å¸‚åœºå½±å“**: çªç ´å°†å¸¦åŠ¨è„‘ç§‘å­¦ã€åŒ»ç–—ç§‘æŠ€æ¿å—
â€¢ **æŠ•èµ„è¦ç‚¹**: å…³æ³¨ä¸´åºŠè¯•éªŒç»“æœã€ç›‘ç®¡è¿›å±•ã€å•†ä¸šåŒ–æ—¶é—´è¡¨""",
            
            'doge': """
ğŸ“Š **Dogecoinäº§ä¸šåˆ†æ**
â€¢ **æ ¸å¿ƒåœ°ä½**: ElonèƒŒä¹¦çš„æœ€å¼ºmemeå¸ï¼Œç¤¾åŒºæ´»è·ƒ
â€¢ **è¿‘æœŸç„¦ç‚¹**: Xå¹³å°æ”¯ä»˜é›†æˆä¼ é—»ã€DOGE-1å«æ˜Ÿä»»åŠ¡
â€¢ **å¸‚åœºå½±å“**: æ¨æ–‡ç›´æ¥å½±å“DOGEä»·æ ¼ï¼ˆÂ±10-20%å¸¸è§ï¼‰
â€¢ **æŠ•èµ„è¦ç‚¹**: å…³æ³¨æ”¯ä»˜é‡‡ç”¨ã€æŠ€æœ¯å‡çº§ã€ç¤¾åŒºçƒ­åº¦ã€ç›‘ç®¡æ€åº¦"""
        }
        return analyses.get(industry_id, "")
    
    def generate_daily_report(self, tweets: List[Dict]) -> str:
        """ç”Ÿæˆæ¯æ—¥æ·±åº¦åˆ†ææŠ¥å‘Š"""
        now = datetime.now()
        period = "æ—©å ±" if now.hour < 12 else "æ™šå ±"
        
        lines = [
            "=" * 70,
            f"ğŸš€ Elon Musk æ¨æ–‡æ·±åº¦åˆ†æ | {period}",
            f"ğŸ“… {now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}",
            "=" * 70,
            ""
        ]
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_tweets = len(tweets)
        if total_tweets == 0:
            lines.append("ğŸ“­ æœ¬æ—¶æ®µæ— æ–°æ¨æ–‡")
            return "\n".join(lines)
        
        # æŒ‰äº§ä¸šåˆ†ç±»æ¨æ–‡
        industry_tweets = {ind_id: [] for ind_id in self.industries.keys()}
        industry_tweets['other'] = []
        
        for tweet in tweets:
            text = tweet.get('text', '')
            industries = self.analyze_tweet_industry(text)
            
            if industries:
                for ind in industries:
                    for ind_id, info in self.industries.items():
                        if info['name'] == ind['name']:
                            industry_tweets[ind_id].append(tweet)
                            break
            else:
                industry_tweets['other'].append(tweet)
        
        # ç”Ÿæˆäº§ä¸šåˆ†ææŠ¥å‘Š
        lines.append(f"ğŸ“Š æœ¬æ—¶æ®µå…± **{total_tweets}** æ¡æ¨æ–‡\n")
        
        # æŒ‰é‡è¦æ€§æ’åºäº§ä¸š
        priority_order = ['tesla', 'doge', 'xai', 'spacex', 'neuralink', 'twitter', 'boring', 'other']
        
        for ind_id in priority_order:
            tweets_in_ind = industry_tweets.get(ind_id, [])
            if not tweets_in_ind:
                continue
            
            if ind_id == 'other':
                lines.append("\n" + "â”€" * 70)
                lines.append("ğŸ“ å…¶ä»–æ¨æ–‡")
                lines.append("â”€" * 70)
            else:
                industry_info = self.industries[ind_id]
                lines.append("\n" + "â”€" * 70)
                lines.append(f"{industry_info['name']} [{len(tweets_in_ind)}æ¡]")
                lines.append("â”€" * 70)
                
                # æ·»åŠ äº§ä¸šåˆ†æ
                analysis = self.get_industry_analysis(ind_id)
                if analysis:
                    lines.append(analysis)
                    lines.append("")
            
            # åˆ—å‡ºç›¸å…³æ¨æ–‡
            for i, tweet in enumerate(tweets_in_ind[:3], 1):  # æ¯ä¸ªäº§ä¸šæœ€å¤š3æ¡
                text = tweet.get('text', '')[:100]
                likes = tweet.get('likeCount', 0)
                retweets = tweet.get('retweetCount', 0)
                time = tweet.get('createdAt', '')
                
                lines.append(f"  {i}. {text}...")
                lines.append(f"     â¤ï¸{likes} ğŸ”„{retweets} | {time}")
                lines.append("")
        
        # æ€»ç»“ä¸å±•æœ›
        lines.append("\n" + "=" * 70)
        lines.append("ğŸ”® æ€»ç»“ä¸å±•æœ›")
        lines.append("=" * 70)
        
        # æ‰¾å‡ºæœ€æ´»è·ƒäº§ä¸š
        active_industries = [(k, len(v)) for k, v in industry_tweets.items() if len(v) > 0 and k != 'other']
        if active_industries:
            active_industries.sort(key=lambda x: x[1], reverse=True)
            top_ind = active_industries[0]
            ind_name = self.industries[top_ind[0]]['name']
            lines.append(f"\nğŸ“Œ æœ¬æ—¶æ®µæœ€æ´»è·ƒäº§ä¸š: {ind_name} ({top_ind[1]}æ¡)")
            
            # æŠ•èµ„å»ºè®®æç¤º
            if top_ind[0] == 'tesla':
                lines.append("ğŸ’¡ å…³æ³¨TSLAè‚¡ä»·æ³¢åŠ¨ï¼Œé‡è¦äº§å“/äº¤ä»˜ä¿¡æ¯å¯èƒ½å¼•å‘Â±5%æ³¢åŠ¨")
            elif top_ind[0] == 'doge':
                lines.append("ğŸ’¡ DOGEå¯èƒ½è¿æ¥æ³¢åŠ¨ï¼Œå…³æ³¨æ”¯ä»˜é‡‡ç”¨è¿›å±•å’Œç¤¾åŒºååº”")
            elif top_ind[0] == 'xai':
                lines.append("ğŸ’¡ AIå™äº‹çƒ­åº¦ä¸Šå‡ï¼Œå…³æ³¨ç§‘æŠ€è‚¡æ•´ä½“æƒ…ç»ªå’ŒGrokè¿›å±•")
        
        lines.append("\n" + "=" * 70)
        lines.append("ğŸ¦ åˆ†æ by é¾™è™¾Agent | æ•°æ®æ¥è‡ªAgent Browserç›‘æ§")
        lines.append("=" * 70)
        
        return "\n".join(lines)


def main():
    """ä¸»å‡½æ•° - ç”ŸæˆæŠ¥å‘Š"""
    # è¿™é‡Œåº”è¯¥ä»å®é™…å­˜å‚¨çš„æ¨æ–‡æ•°æ®ä¸­è¯»å–
    # æš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºæ ¼å¼
    
    analyzer = ElonIndustryAnalyzer()
    
    # æ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…åº”ä»æ–‡ä»¶/æ•°æ®åº“è¯»å–ï¼‰
    sample_tweets = [
        {
            'text': 'Tesla FSD v12 is amazing! Autopilot getting better every day.',
            'likeCount': 4500,
            'retweetCount': 800,
            'createdAt': '2026-02-12 07:30'
        },
        {
            'text': 'Grok is learning fast. xAI team doing great work.',
            'likeCount': 3200,
            'retweetCount': 500,
            'createdAt': '2026-02-12 06:15'
        },
        {
            'text': 'Starship launch window looking good for next week.',
            'likeCount': 8900,
            'retweetCount': 2100,
            'createdAt': '2026-02-12 05:45'
        }
    ]
    
    report = analyzer.generate_daily_report(sample_tweets)
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = f"/tmp/elon_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")


if __name__ == "__main__":
    main()
