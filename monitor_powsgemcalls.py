#!/usr/bin/env python3
"""
ç›‘æ§ t.me/PowsGemCalls é¢‘é“
å­¦ä¹ ç›®æ ‡ï¼šGemç‹©çŒæ–¹æ³•è®º
æ¨é€ï¼šæ–°å†…å®¹å³æ—¶é€šçŸ¥
"""

import os
import re
import json
from datetime import datetime
from typing import List, Dict, Tuple

class PowsGemCallsMonitor:
    """Pow's Gem Calls é¢‘é“ç›‘æ§å™¨"""
    
    def __init__(self):
        self.channel_url = "https://t.me/s/PowsGemCalls"
        self.data_file = "/tmp/pows_gem_calls_last.json"
        self.db_file = "/tmp/pows_gem_calls_db.json"
    
    def fetch_latest_posts(self) -> List[Dict]:
        """è·å–é¢‘é“æœ€æ–°å¸–å­ï¼ˆé€šè¿‡ç½‘é¡µæŠ“å–ï¼‰"""
        import urllib.request
        
        # å°è¯•å¤šä¸ªæ•°æ®æº
        urls_to_try = [
            # 1. ç›´æ¥æŠ“å– Telegram å…¬å¼€é¢‘é“
            ("https://t.me/s/PowsGemCalls", "html"),
            # 2. å¤‡ç”¨ï¼šä½¿ç”¨ r.jina.ai æå–
            ("https://r.jina.ai/http://t.me/s/PowsGemCalls", "text"),
        ]
        
        for url, content_type in urls_to_try:
            try:
                req = urllib.request.Request(url, headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                })
                
                with urllib.request.urlopen(req, timeout=30) as resp:
                    content = resp.read().decode('utf-8')
                    if content_type == "html":
                        return self._parse_html_posts(content)
                    else:
                        return self._parse_simple(content)
            except Exception as e:
                print(f"Failed to fetch from {url}: {e}")
                continue
        
        return []
    
    def _parse_html_posts(self, html: str) -> List[Dict]:
        """è§£æHTMLæå–å¸–å­"""
        posts = []
        
        # Telegram ç½‘é¡µç‰ˆçš„æ¶ˆæ¯ç»“æ„
        # å°è¯•æå–æ¶ˆæ¯å†…å®¹
        import re
        
        # æŸ¥æ‰¾æ¶ˆæ¯æ–‡æœ¬
        # Telegram ç½‘é¡µç‰ˆçš„æ¶ˆæ¯é€šå¸¸åœ¨ç‰¹å®šclassä¸­
        message_pattern = r'class="tgme_widget_message_text[^"]*"[^>]*>(.*?)</div>'
        messages = re.findall(message_pattern, html, re.DOTALL)
        
        for msg_html in messages:
            # æ¸…ç†HTMLæ ‡ç­¾
            text = re.sub(r'<[^>]+>', '', msg_html)
            text = text.replace('&quot;', '"').replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
            text = text.strip()
            
            if text and len(text) > 10:
                post = {
                    "text": text,
                    "contracts": [],
                    "links": []
                }
                
                # æå–åˆçº¦åœ°å€
                contract_pattern = r'0x[a-fA-F0-9]{40}'
                post["contracts"] = re.findall(contract_pattern, text)
                
                # æå–é“¾æ¥
                link_pattern = r'https?://[^\s<>"]+'
                post["links"] = re.findall(link_pattern, text)
                
                posts.append(post)
        
        return posts
    
    def _parse_simple(self, text: str) -> List[Dict]:
        """ç®€å•æ–‡æœ¬è§£æ"""
        posts = []
        lines = text.split('\n')
        current_post = {"text": "", "contracts": [], "links": []}
        
        for line in lines:
            line = line.strip()
            if not line:
                if current_post["text"]:
                    posts.append(current_post)
                    current_post = {"text": "", "contracts": [], "links": []}
                continue
            
            current_post["text"] += line + "\n"
            
            # æå–åˆçº¦åœ°å€
            contract_pattern = r'0x[a-fA-F0-9]{40}'
            contracts = re.findall(contract_pattern, line)
            current_post["contracts"].extend(contracts)
            
            # æå–é“¾æ¥
            link_pattern = r'https?://[^\s]+'
            links = re.findall(link_pattern, line)
            current_post["links"].extend(links)
        
        if current_post["text"]:
            posts.append(current_post)
        
        return posts
    
    def extract_gem_call(self, post: Dict) -> Dict:
        """æå–Gem Callçš„ç»“æ„åŒ–ä¿¡æ¯"""
        text = post.get("text", "")
        
        # åˆ†æå†…å®¹ç±»å‹
        call_type = self._classify_content(text)
        
        # æå–å…³é”®ä¿¡æ¯
        info = {
            "raw_text": text[:500],
            "type": call_type,
            "contracts": post.get("contracts", []),
            "links": post.get("links", []),
            "extracted_at": datetime.now().isoformat()
        }
        
        # å¦‚æœæ˜¯Gem Callï¼Œæå–æ›´å¤šç»†èŠ‚
        if call_type == "gem_call":
            info["chain"] = self._detect_chain(text)
            info["sentiment"] = self._detect_sentiment(text)
            info["narrative"] = self._extract_narrative(text)
        
        return info
    
    def _classify_content(self, text: str) -> str:
        """åˆ†ç±»å†…å®¹ç±»å‹"""
        text_lower = text.lower()
        
        if any(kw in text_lower for kw in ['gem', 'call', 'moon', '100x', 'alpha']):
            return "gem_call"
        elif any(kw in text_lower for kw in ['update', 'sold', 'tp', 'take profit']):
            return "position_update"
        elif any(kw in text_lower for kw in ['warning', 'rug', 'honeypot', 'scam']):
            return "warning"
        elif len(text) < 50:
            return "short_update"
        else:
            return "analysis"
    
    def _detect_chain(self, text: str) -> str:
        """æ£€æµ‹é“¾"""
        text_lower = text.lower()
        if 'base' in text_lower or 'clanker' in text_lower or 'bankr' in text_lower:
            return "Base"
        elif 'solana' in text_lower or 'sol' in text_lower:
            return "Solana"
        elif 'ethereum' in text_lower or 'eth' in text_lower:
            return "Ethereum"
        elif 'bsc' in text_lower or 'binance' in text_lower:
            return "BSC"
        return "Unknown"
    
    def _detect_sentiment(self, text: str) -> str:
        """æ£€æµ‹æƒ…ç»ª"""
        text_lower = text.lower()
        bullish = ['bullish', 'moon', '100x', 'gem', 'alpha', 'buy', 'long']
        bearish = ['bearish', 'dump', 'rug', 'sell', 'short', 'avoid']
        
        b_count = sum(1 for w in bullish if w in text_lower)
        be_count = sum(1 for w in bearish if w in text_lower)
        
        if b_count > be_count:
            return "ğŸŸ¢ Bullish"
        elif be_count > b_count:
            return "ğŸ”´ Bearish"
        else:
            return "âšª Neutral"
    
    def _extract_narrative(self, text: str) -> str:
        """æå–å™äº‹ä¸»é¢˜"""
        text_lower = text.lower()
        narratives = {
            "AI": ["ai", "agent", "gpt", "claude", "llm"],
            "Meme": ["meme", "pepe", "doge", "shib", "wojak"],
            "DeFi": ["defi", "yield", "farm", "stake", "liquidity"],
            "Gaming": ["game", "gaming", "p2e", "play"],
            "Social": ["social", "friend", "share", "community"]
        }
        
        for nar, keywords in narratives.items():
            if any(kw in text_lower for kw in keywords):
                return nar
        return "Other"
    
    def check_new_content(self) -> Tuple[bool, List[Dict]]:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ–°å†…å®¹"""
        posts = self.fetch_latest_posts()
        
        # è¯»å–ä¸Šæ¬¡è®°å½•
        last_check = []
        if os.path.exists(self.data_file):
            try:
                with open(self.data_file, 'r') as f:
                    last_check = json.load(f)
            except:
                pass
        
        # å¯¹æ¯”æ‰¾æ–°å†…å®¹
        new_posts = []
        last_texts = [p.get("text", "")[:100] for p in last_check]
        
        for post in posts[:5]:  # åªæ£€æŸ¥æœ€è¿‘5æ¡
            post_preview = post.get("text", "")[:100]
            if post_preview not in last_texts:
                new_posts.append(post)
        
        # ä¿å­˜å½“å‰è®°å½•
        with open(self.data_file, 'w') as f:
            json.dump(posts[:10], f, indent=2)
        
        return len(new_posts) > 0, new_posts
    
    def generate_alert(self, posts: List[Dict]) -> str:
        """ç”Ÿæˆæ¨é€å†…å®¹"""
        lines = [
            "ğŸ¯ Pow's Gem Calls æ›´æ–°",
            f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "=" * 50,
            ""
        ]
        
        for i, post in enumerate(posts[:3], 1):
            info = self.extract_gem_call(post)
            
            lines.append(f"\nğŸ”” æ›´æ–° #{i}")
            lines.append(f"ç±»å‹: {info['type']}")
            
            if info['type'] == 'gem_call':
                lines.append(f"é“¾: {info['chain']}")
                lines.append(f"æƒ…ç»ª: {info['sentiment']}")
                lines.append(f"å™äº‹: {info['narrative']}")
            
            lines.append(f"\nå†…å®¹:\n{info['raw_text'][:300]}...")
            
            if info['contracts']:
                lines.append(f"\nğŸ“‹ åˆçº¦åœ°å€:")
                for addr in info['contracts'][:3]:
                    lines.append(f"  {addr}")
            
            if info['links']:
                lines.append(f"\nğŸ”— é“¾æ¥:")
                for link in info['links'][:2]:
                    lines.append(f"  {link}")
            
            lines.append("\n" + "-" * 50)
        
        return "\n".join(lines)
    
    def learn_patterns(self) -> Dict:
        """å­¦ä¹ Powçš„Gemç‹©çŒæ¨¡å¼"""
        posts = self.fetch_latest_posts()
        
        patterns = {
            "total_posts": len(posts),
            "gem_calls": 0,
            "avg_contracts_per_call": 0,
            "preferred_chains": {},
            "common_narratives": {},
            "key_phrases": []
        }
        
        all_contracts = 0
        
        for post in posts:
            info = self.extract_gem_call(post)
            
            if info['type'] == 'gem_call':
                patterns["gem_calls"] += 1
                all_contracts += len(info['contracts'])
                
                chain = info['chain']
                patterns["preferred_chains"][chain] = patterns["preferred_chains"].get(chain, 0) + 1
                
                nar = info['narrative']
                patterns["common_narratives"][nar] = patterns["common_narratives"].get(nar, 0) + 1
        
        if patterns["gem_calls"] > 0:
            patterns["avg_contracts_per_call"] = all_contracts / patterns["gem_calls"]
        
        return patterns
    
    def generate_learning_report(self) -> str:
        """ç”Ÿæˆå­¦ä¹ æŠ¥å‘Š"""
        patterns = self.learn_patterns()
        
        lines = [
            "ğŸ“š Pow's Gem Calls å­¦ä¹ æŠ¥å‘Š",
            f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "=" * 50,
            "",
            f"ğŸ“Š ç»Ÿè®¡æ•°æ®:",
            f"  æ€»å¸–å­: {patterns['total_posts']}",
            f"  Gem Calls: {patterns['gem_calls']}",
            f"  å¹³å‡æ¯Callåˆçº¦æ•°: {patterns['avg_contracts_per_call']:.1f}",
            "",
            f"â›“ï¸ åå¥½é“¾:",
        ]
        
        for chain, count in sorted(patterns['preferred_chains'].items(), key=lambda x: -x[1]):
            lines.append(f"  {chain}: {count}")
        
        lines.extend([
            "",
            f"ğŸ“– å¸¸è§å™äº‹:",
        ])
        
        for nar, count in sorted(patterns['common_narratives'].items(), key=lambda x: -x[1]):
            lines.append(f"  {nar}: {count}")
        
        lines.extend([
            "",
            "ğŸ’¡ å­¦ä¹ è¦ç‚¹:",
            "  1. Powå…³æ³¨ä»€ä¹ˆé“¾çš„gemï¼Ÿ",
            "  2. ä»€ä¹ˆå™äº‹æœ€å®¹æ˜“è¢«æåŠï¼Ÿ",
            "  3. å¦‚ä½•å¿«é€Ÿåˆ¤æ–­ä¸€ä¸ªcallçš„è´¨é‡ï¼Ÿ",
            "  4. ä»€ä¹ˆæ—¶æœºå…¥åœº/å‡ºåœºï¼Ÿ",
        ])
        
        return "\n".join(lines)


def main():
    """ä¸»å‡½æ•°"""
    monitor = PowsGemCallsMonitor()
    
    # æ£€æŸ¥æ–°å†…å®¹
    has_new, new_posts = monitor.check_new_content()
    
    if has_new:
        alert = monitor.generate_alert(new_posts)
        print(alert)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        filename = f"/tmp/pows_alert_{datetime.now().strftime('%Y%m%d_%H%M')}.txt"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(alert)
        print(f"\nğŸ’¾ æ¨é€å·²ä¿å­˜: {filename}")
    else:
        print("ğŸ“­ æš‚æ— æ–°å†…å®¹")
    
    # ç”Ÿæˆå­¦ä¹ æŠ¥å‘Š
    report = monitor.generate_learning_report()
    report_file = f"/tmp/pows_learning_{datetime.now().strftime('%Y%m%d')}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"ğŸ“š å­¦ä¹ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")


if __name__ == "__main__":
    main()
